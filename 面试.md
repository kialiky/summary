# 一、面向对象三大特性五大原则 + 低耦合高内聚

面向对象的三大特性是"封装、"多态"、"继承"，五大原则是"单一职责原则"、"开放封闭原则"、"里氏替换原则"、"依赖倒置原则"、"接口分离原则"。

# 二、Java

## 深克隆和浅克隆

**浅克隆**：创建一个新对象，新对象的属性和原来对象完全相同，对于非基本类型属性，仍指向原有属性所指向的对象的内存地址。

**深克隆**：创建一个新对象，属性中引用的其他对象也会被克隆，不再指向原有对象地址。

总之深浅克隆都会在堆中新分配一块区域，区别在于对象属性引用的对象是否需要进行克隆（递归性的）。

## final、finally、finalize

### final

final关键字可以用来修饰类、方法和变量

1. 当用final修饰一个类时，表明这个类不能被**继承**。

2. final修饰的方法表示此方法已经是“最后的、最终的”含义，亦即此方法不能被**重写**（可以重载多个final修饰的方法）。此处需要注意的一点是：因为重写的前提是子类可以从父类中继承此方法，如果父类中final修饰的方法同时访问控制权限为private，将会导致子类中不能直接继承到此方法，因此，此时可以在子类中定义相同的方法名和参数，此时不再产生重写与final的矛盾，而是在子类中重新定义了新的方法。

3.  final**成员变量表示常量，只能被赋值一次，赋值后值不再改变。**

   当final修饰一个**基本数据类型**时，表示该基本数据类型的值一旦在初始化后便不能发生变化；如果final修饰一个**引用类型**时，则在对其初始化之后便不能再让其指向其他对象了，但该引用所指向的对象的内容是可以发生变化的。本质上是一回事，因为引用的值是一个地址，final要求值，即地址的值不发生变化。

　　**final修饰一个成员变量（属性），必须要显示初始化。这里有两种初始化方式**，一种是在变量声明的时候初始化；第二种方法是在声明变量的时候不赋初值，但是要在这个变量所在的类的所有的构造函数中对这个变量赋初值。

### finally

finally是对Java异常处理模型的最佳补充。finally结构使代码总会执行，而不管无异常发生。使用finally可以维护对象的内部状态，并可以清理非内存资源。特别是在关闭数据库连接这方面，如果程序员把数据库连接的close()方法放到finally中，就会大大降低程序出错的几率。

### finalize

Java技术使用finalize()方法在垃圾收集器将对象从内存中清除出去前，做必要的清理工作。这个方法是由垃圾收集器在确定这个对象没被引用时对这个对象调用的。它是在Object类中定义的，因此所的类都继承了它。子类覆盖finalize()方法以整理系统资源或者执行其他清理工作。finalize()方法是在垃圾收集器删除对象之前对这个对象调用的。

## List

1. ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。 （LinkedList是双向链表，有next也有previou)
2. 对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。  
3. 对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。

## static

static是java中非常重要的一个关键字，而且它的用法也很丰富，主要有四种用法：

1. 用来修饰**成员变量**，将其变为类的成员，从而实现所有对象对于该成员的共享；
2. 用来修饰**成员方法**，将其变为类方法，可以直接使用**“类名.方法名”**的方式调用，常用于工具类；
3. 静态块用法，将多个类成员放在一起**初始化**，使得程序更加规整，其中理解对象的初始化过程非常关键；
4. 静态导包用法，将类的方法直接导入到当前类中，从而直接使用**“方法名”**即可调用类方法，更加方便。

## 接口

Java接口：是一系列**方法的声明**，是一些**方法特征的集合**，一个接口只有方法的特征没有方法的实现，因此这些方法可以在不同的地方被不同的类实现，而这些实现可以具有不同的行为（功能）。

接口作用如下：

1、**丰富Java面向对象的思想**：在Java语言中， abstract class 和interface 是支持抽象类定义的两种机制。正是由于这两种机制的存在，才赋予了Java强大的面向对象能力。

2、**提供简单、规范性**：如果一个项目比较庞大，那么就需要一个能理清所有业务的架构师来定义一些主要的接口，这些接口不仅告诉开发人员你需要实现那些业务，而且也将命名规范限制住了（防止一些开发人员随便命名导致别的程序员无法看明白）。

3、**提高维护、拓展性**：比如你要做一个画板程序，其中里面有一个面板类，主要负责绘画功能，然后你就这样定义了这个类，可是在不久将来，你突然发现这个类满足不了你了，然后你又要重新设计这个类，更糟糕是你可能要放弃这个类，那么其他地方可能有引用他，这样修改起来很麻烦，如果你一开始定义一个接口，把绘制功能放在接口里，然后定义类时实现这个接口，然后你只要用这个接口去引用实现它的类就行了，以后要换的话只不过是引用另一个类而已，这样就达到维护、拓展的方便性。

4、**增强安全、严密性**：接口是实现软件松耦合的重要手段，它描叙了系统对外的所有服务，而不涉及任何具体的实现细节。这样就比较安全、严密一些(一般软件服务商考虑的比较多)。

关于接口的使用规范：

1、接口中可以定义常量，不能定义变量，如果你在接口中定义属性，那么通过反编译可以看见他会自动用public static final 修饰，接口中的属性都是**全局静态常量**，接口中的常量必须在定义时指定初始值。

2、 接口中所有的方法都是抽象方法，接口中方法都会自动用**public abstract** 修饰，即接口中只有**全局抽象**方法。

3、 接口不能实例化，接口中不能有构造。

4、 接口之间可以通过extends实现继承关系，一个接口可以继承多个接口，但接口不能继承类。

5、 接口的实现类必须实现接口的全部方法，否则必须定义为抽象类。

### 抽象类和接口的区别

含有abstract修饰符的class即为抽象类，abstract 类不能创建实例对象。含有abstract方法的类必须定义为abstract class，abstract class类中的方法不必是抽象的。abstract class类中定义抽象方法必须在具体(Concrete)子类中实现，所以，不能有抽象构造方法或抽象静态方法。如果子类没有实现抽象父类中的所有抽象方法，那么子类也必须定义为abstract类型。

接口（interface）可以说成是抽象类的一种特例，接口中的所有方法都必须是抽象的。接口中的方法定义默认为public abstract类型，接口中的成员变量类型默认为**public static final**。

下面比较一下两者的语法区别：

1. 抽象类可以有**构造方法**，接口中不能有构造方法。
2. 抽象类中可以有普通成员变量，接口中没有普通成员变量
3. 抽象类中可以包含**非抽象的普通方法**，接口中的所有方法必须都是抽象的，不能有非抽象的普通方法。
4. 抽象类中的抽象方法的访问类型可以是public，protected和（默认类型,虽然eclipse下不报错，但应该也不行），但接口中的抽象方法只能是public类型的，并且默认即为public abstract类型。

5. 抽象类中可以包含静态方法，接口中不能包含静态方法
6. 抽象类和接口中都可以包含静态成员变量，抽象类中的静态成员变量的访问类型可以任意，但接口中定义的变量只能是public static final类型，并且默认即为public static final类型。
7. **一个类可以实现多个接口，但只能继承一个抽象类**

## 反射

JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；这种动态获取信息以及动态调用对象方法的功能称为java语言的反射机制。

### 获取字节码的方式

在Java 中可以通过三种方法获取类的字节码(Class)对象

- **对象.getClass()**: 通过Object 类中的getClass() 方法，想要用这种方法必须要明确具体的类并且创建该类的对象。
- **类.class**: 所有数据类型都具备一个静态的属性.class 来获取对应的Class 对象。但是还是要明确到类，然后才能调用类中的静态成员。
- **Class.forName("指定类的全限定名")**: 只要通过给定类的字符串名称就可以获取该类的字节码对象，这样做扩展性更强。通过Class.forName() 方法完成，必须要指定类的全限定名，由于前两种方法都是在知道该类的情况下获取该类的字节码对象，因此不会有异常，但是Class.forName() 方法如果写错类的路径会报 ClassNotFoundException 的异常。

```java
ackage com.jas.reflect;

public class ReflectTest {
    public static void main(String[] args) {

        Fruit fruit = new Fruit();
        Class<?> class1 = fruit.getClass();     //方法一

        Class<?> class2 = Fruit.class;     //方法二

        Class class3 = null;     
        try {    //方法三，如果这里不指定类所在的包名会报 ClassNotFoundException 异常
            class3 = Class.forName("com.jas.reflect.Fruit");
        } catch (ClassNotFoundException e) {
            e.printStackTrace();
        }

        System.out.println(class1 + "  " +class2 + "    " + class3);
    }
}
class Fruit{}
```

### 通过反射机制获取类信息

通过反射机制创建对象，在创建对象之前要获得对象的构造函数对象，通过构造函数对象创建对应类的实例。

下面这段代码分别在运行期间创建了一个无参与有参的对象实例。由于getConstructor() 方法与newInstance() 方法抛出了很多异常(你可以通过源代码查看它们)，这里就简写了直接抛出一个Exception，下同。

```java
package com.jas.reflect;

import java.lang.reflect.Constructor;

public class ReflectTest {
    public static void main(String[] args) throws Exception {

        Class clazz = null;
        clazz = Class.forName("com.jas.reflect.Fruit");
        Constructor<Fruit> constructor1 = clazz.getConstructor();
        Constructor<Fruit> constructor2 = clazz.getConstructor(String.class);

        Fruit fruit1 = constructor1.newInstance();
        Fruit fruit2 = constructor2.newInstance("Apple");

    }
}

class Fruit{
    public Fruit(){
        System.out.println("无参构造器Run...........");
    }
    public Fruit(String type){
        System.out.println("有参构造器Run..........." + type);
    }

}
```

通过反射机制获取Class 中的属性

```java
package com.jas.reflect;

import java.lang.reflect.Field;

public class ReflectTest {
    public static void main(String[] args) throws Exception {

        Class<?> clazz = null;
        Field field = null;

        clazz = Class.forName("com.jas.reflect.Fruit");
        //field = clazz.getField("num");       getField() 方法不能获取私有的属性
        // field = clazz.getField("type");     访问私有字段时会报 NoSuchFieldException异常
        field = clazz.getDeclaredField("type");     //获取私有type 属性
        field.setAccessible(true);  //对私有字段的访问取消检查
        Fruit fruit = (Fruit) clazz.newInstance();  //创建无参对象实例
        field.set(fruit,"Apple");   //为无参对象实例属性赋值
        Object type = field.get(fruit); //通过fruit 对象获取属性值

        System.out.println(type);
    }
}

class Fruit{
    public int num;
    private String type;

    public Fruit(){
        System.out.println("无参构造器Run...........");
    }
    public Fruit(String type){
        System.out.println("有参构造器Run..........." + type);
    }

}
```



## Java特性

### 1、封装(Encapsulation) ：　

封装：是指隐藏对象的属性和实现细节，仅对外提供公共访问方式。

好处：
• 将变化隔离。
• 便于使用。
• 提高重用性。
• 提高安全性。

封装原则：
• 将不需要对外提供的内容都隐藏起来。
• 把属性都隐藏，提供公共方法对其访问 。

### 2、继承

继承是面向对象最显著的一个特性。 继承是从已有的类中派生出新的类， 新的类能吸收已有类的数据属性和行为，并能扩展新的能力。
在JAVA中， 被继承的类叫父类(parent class)或超类(superclass)， 继承父类的类叫子类(subclass)或派生类(derivedclass)。 因此， 子类是父类的一个专门用途的版本， 它继承了父类中定义的所有实例变量和方法， 并且增加了独特的元素 。

### **3、多态(polymorphism)** 

在面向对象语言中， 多态性是指一个方法可以有多种实现版本，即“一种定义， 多种实现”。 利用多态可以设计和实现可扩展的系统， 只要新类也在继承层次中。 新的类对程序的通用部分只需进行很少的修改， 或不做修改。 类的多态性表现为方法的多态性，方法的多态性主要有方法的重载和方法的覆盖。

方法**重载**(overload)是指在同一个类中的多个方法可以同名但参数列表必须不同。 重载表现为同一个类中方法的多态性。

方法**重写**(override)是指子类重定义了父类中同名的方法。 重写表现为父子与子类之间方法的多态性。

## Java 优点

简单性、面向对象、分布式、解释型、可靠、安全、平台无关、可移植、高性能、多线程、动态性等

**可靠性和安全性**

Java最初设计目的是应用于电子类消费产品，因此要求较高的可靠性。Java虽然源于C++，但它消除了许多C++不可靠因素，可以防止许多编程错误。首先，Java是强类型的语言，要求显式的方法声明，这保证了编译器可以发现方法调用错误，保证程序更加可靠；其次，Java不支持指针，这杜绝了内存的非法访问；第三，Java的自动单元收集防止了内存丢失等动态内存分配导致的问题；第四，Java解释器运行时实施检查，可以发现数组和字符串访问的越界，最后，Java提供了异常处理机制，程序员可以把一组错误代码放在一个地方，这样可以简化错误处理任务便于恢复。 

由于Java主要用于网络应用程序开发，因此对安全性有较高的要求。如果没有安全保证，用户从网络下载程序执行就非常危险。Java通过自己的安全机制防止了病毒程序的产生和下载程序对本地系统的威胁破坏。当Java字节码进入解释器时，首先必须经过字节码校验器的检查，然后，Java解释器将决定程序中类的内存布局，随后，类装载器负责把来自网络的类装载到单独的内存区域，避免应用程序之间相互干扰破坏。最后，客户端用户还可以限制从网络上装载的类只能访问某些文件系统。 

上述几种机制结合起来，使得Java成为安全的编程语言。 

**多线程** 

线程是操作系统的一种新概念，它又被称作轻量进程，是比传统进程更小的可并发执行的单位。 

C和C++采用单线程体系结构，而Java却提供了多线程支持。 

Java在两方面支持多线程。一方面，Java环境本身就是多线程的。若干个系统线程运行负责必要的无用单元回收，系统维护等系统级操作；另一方面，Java语言内置多线程控制，可以大大简化多线程应用程序开发。Java提供了一个类Thread，由它负责启动运行，终止线程，并可检查线程状态。Java的线程还包括一组同步原语。这些原语负责对线程实行并发控制。利用Java的多线程编程接口，开发人员可以方便得写出支持多线程的应用程序，提高程序执行效率。必须注意地是，Java的多线程支持在一定程度上受运行时支持平台的限制。例如，如果操作系统本身不支持多线程，Java的多线程特性可能就表现不出来。

## Java死锁

模拟两个资源：

```
public class ThreadResource
{
    public static Object resource1 = new Object();
    
    public static Object resource2 = new Object();
}
```

**模拟线程1占用资源1并申请获得资源2的锁：**

```java
public class Thread1 implements Runnable
{
    
    @Override
    public void run()
    {
        try
        {
            System.out.println("Thread1 is running");
            synchronized (ThreadResource.resource1)
            {
                System.out.println("Thread1 lock resource1");
                Thread.sleep(2000);//休眠2s等待线程2锁定资源2
                synchronized (ThreadResource.resource2)
                {
                    System.out.println("Thread1 lock resource2");
                }
                System.out.println("Thread1 release resource2");
            }
            System.out.println("Thread1 release resource1");
        }
        catch (Exception e)
        {
            System.out.println(e.getMessage());
        }
        System.out.println("Thread1 is stop");
    }
    
}
```

**模拟线程2占用资源2并申请获得资源1的锁：**

```java
public class Thread1 implements Runnable
{
    
    @Override
    public void run()
    {
        try
        {
            System.out.println("Thread1 is running");
            synchronized (ThreadResource.resource1)
            {
                System.out.println("Thread1 lock resource1");
                Thread.sleep(2000);//休眠2s等待线程2锁定资源2
                synchronized (ThreadResource.resource2)
                {
                    System.out.println("Thread1 lock resource2");
                }
                System.out.println("Thread1 release resource2");
            }
            System.out.println("Thread1 release resource1");
        }
        catch (Exception e)
        {
            System.out.println(e.getMessage());
        }
        System.out.println("Thread1 is stop");
    }
    
}
```

**同时运行俩个线程：**

```java
public class ThreadTest
{
    public static void main(String[] args)
    {
       new Thread(new Thread1()).start();
       new Thread(new Thread2()).start();
    }
}
```

**最后输出结果是：**

Thread1 is running
Thread2 is running
Thread1 lock resource1
Thread2 lock resource2

并且程序一直无法结束。这就是由于线程1占用了资源1，此时线程2已经占用资源2。这个时候线程1想要使用资源2，线程2想要使用资源1,。两个线程都无法让步，导致程序死锁。

### java避免死锁的解决意见

由上面的例子可以看出当线程在同步某个对象里，再去锁定另外一个对象的话，就和容易发生死锁的情况。最好是线程**每次只锁定一个对象并且在锁定该对象的过程中不再去锁定其他的对象**，这样就不会导致死锁了。比如将以上的线程改成下面这种写法就可以避免死锁：

```java
public void run()
    {
        try
        {
            System.out.println("Thread1 is running");
            synchronized (ThreadResource.resource1)
            {
                System.out.println("Thread1 lock resource1");
                Thread.sleep(2000);//休眠2s等待线程2锁定资源2
            }
            System.out.println("Thread1 release resource1");
            synchronized (ThreadResource.resource2)
            {
                System.out.println("Thread1 lock resource2");
            }
            System.out.println("Thread1 release resource2");
        }
        catch (Exception e)
        {
            System.out.println(e.getMessage());
        }
        System.out.println("Thread1 is stop");
    }
```

但是有的时候业务需要同时去锁定两个对象，比如转账业务：A给B转账，需要同时锁定A、B两个账户。如果A、B相互同时转账的话就会出现死锁的情况。这时可以定义一个规则：锁定账户先后的规则。根据账户的某一个属性（比如id或者hasCode），判断锁定的先后。即每一次转账业务都是先锁定A再锁定B（或者先锁定B在锁定A），这样也不会导致死锁的发生。比如按照上面的例子，需要同时锁定两个资源，可以根据资源的hashcode值大小来判断先后锁定顺序。可以这样改造线程：

```java
public class Thread3 implements Runnable
{
    
    @Override
    public void run()
    {
        try
        {
            System.out.println("Thread is running");
            if ( ThreadResource.resource1.hashCode() > ThreadResource.resource2.hashCode() )
            {
                //先锁定resource1
                synchronized (ThreadResource.resource1)
                {
                    System.out.println("Thread lock resource1");
                    Thread.sleep(2000);
                    synchronized (ThreadResource.resource2)
                    {
                        System.out.println("Thread lock resource2");
                    }
                    System.out.println("Thread release resource2");
                }
                System.out.println("Thread release resource1");
            }
            else
            {
                //先锁定resource2
                synchronized (ThreadResource.resource2)
                {
                    System.out.println("Thread lock resource2");
                    Thread.sleep(2000);
                    synchronized (ThreadResource.resource1)
                    {
                        System.out.println("Thread lock resource1");
                    }
                    System.out.println("Thread release resource1");
                }
                System.out.println("Thread release resource2");
            }
        }
        catch (Exception e)
        {
            System.out.println(e.getMessage());
        }
        System.out.println("Thread1 is stop");
    }
    
}
```

**总结：死锁常见于，线程在锁定对象还没释放时，又需要锁定另一个对象，并且此时该对象可能被另一个线程锁定。这种时候很容易导致死锁。因此在开发时需要慎重使用锁，尤其是需要注意尽量不要在锁里又加锁。**

## String、StringBuffer、StringBuilder

1. 首先说运行速度，或者说是执行速度，**在这方面运行速度快慢为：StringBuilder > StringBuffer > String**

　　**String最慢的原因：**

　　**String为字符串常量，而StringBuilder和StringBuffer均为字符串变量，即String对象一旦创建之后该对象是不可更改的，但后两者的对象是变量，是可以更改的。**

2. 再来说线程安全

**在线程安全上，StringBuilder是线程不安全的，而StringBuffer是线程安全的**

如果一个StringBuffer对象在字符串缓冲区被多个线程使用时，StringBuffer中很多方法可以带有**synchronized**关键字，所以可以保证线程是安全的，但StringBuilder的方法则没有该关键字，所以不能保证线程安全，有可能会出现一些错误的操作。所以如果要进行的操作是多线程的，那么就要使用StringBuffer，但是在单线程的情况下，还是建议使用速度比较快的StringBuilder。

3. 总结一下

   **String：适用于少量的字符串操作的情况**

   **StringBuilder：适用于单线程下在字符缓冲区进行大量操作的情况**

　　**StringBuffer：适用多线程下在字符缓冲区进行大量操作的情况**

## HashMap

### 结构

<https://blog.csdn.net/qq_38182963/article/details/78940047>

### 为什么使用 hashcode

hashCode 存在的第一重要的原因就是在 HashMap(HashSet 其实就是HashMap) 中使用（其实Object 类的 hashCode 方法注释已经说明了 ），我知道，HashMap 之所以速度快，因为他使用的是散列表，根据 key 的 hashcode 值生成数组下标（通过内存地址直接查找，没有任何判断），时间复杂度完美情况下可以达到 n1（和数组相同，但是比数组用着爽多了，但是需要多出很多内存，相当于以空间换时间）。

### String 类型的 hashcode 方法

String类使用下列算法计算散列码：

int hash = 0；

for (int i =0; i< length();i++)

hash = 31 * hash +charAt(i);

### 为什么大部分 hashcode 方法使用 31

之所以使用 31， 是因为他是一个奇素数。如果乘数是偶数，并且乘法溢出的话，信息就会丢失，因为与2相乘等价于移位运算（低位补0）。使用素数的好处并不很明显，但是习惯上使用素数来计算散列结果。 31 有个很好的性能，即用移位和减法来代替乘法，可以得到更好的性能： 31 * i == (i << 5） - i， 现代的 VM 可以自动完成这种优化。这个公式可以很简单的推导出来。

## HashMap 的 hash 算法的实现原理（为什么右移 16 位，为什么要使用 ^ 位异或）

 HashMap 的 hash 算法（JDK 8）

```java
 static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
```

乍看一下就是简单的异或运算和右移运算，但是为什么要异或呢？为什么要移位呢？而且移位16？

在分析这个问题之前，我们需要先看看另一个事情，什么呢？就是 HashMap 如何根据 hash 值找到数组种的对象，我们看看 get 方法的代码：

```java
final Node<K,V> getNode(int hash, Object key) {
        Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
        if ((tab = table) != null && (n = tab.length) > 0 &&
            // 我们需要关注下面这一行
            (first = tab[(n - 1) & hash]) != null) {
            if (first.hash == hash && // always check first node
                ((k = first.key) == key || (key != null && key.equals(k))))
                return first;
            if ((e = first.next) != null) {
                if (first instanceof TreeNode)
                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);
                do {
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        return e;
                } while ((e = e.next) != null);
            }
        }
        return null;
    }
```

我们看看代码中注释下方的一行代码：first = tab[(n - 1) & hash])。

使用数组长度减一 与运算 hash 值。这行代码就是为什么要让前面的 hash 方法移位并异或。

我们分析一下：

首先，假设有一种情况，对象 A 的 hashCode 为 1000010001110001000001111000000，对象 B 的 hashCode 为 0111011100111000101000010100000。

如果数组长度是16，也就是 15 与运算这两个数， 你会发现结果都是0。这样的散列结果太让人失望了。很明显不是一个好的散列算法。

但是如果我们将 hashCode 值右移 16 位，也就是取 int 类型的一半，刚好将该二进制数对半切开。并且使用位异或运算（如果两个数对应的位置相反，则结果为1，反之为0），这样的话，就能避免我们上面的情况的发生。

总的来说，使用位移 16 位和 异或 就是防止这种极端情况。但是，该方法在一些极端情况下还是有问题，比如：10000000000000000000000000 和 1000000000100000000000000 这两个数，如果数组长度是16，那么即使右移16位，在异或，hash 值还是会重复。但是为了性能，对这种极端情况，JDK 的作者选择了性能。毕竟这是少数情况，为了这种情况去增加 hash 时间，性价比不高。

### HashMap 为什么使用 & 与运算代替模运算？

好了，知道了 hash 算法的实现原理还有他的一些取舍，我们再看看刚刚说的那个根据hash计算下标的方法：

tab[(n - 1) & hash]；

其中 n 是数组的长度。其实该算法的结果和模运算的结果是相同的。但是，对于现代的处理器来说，除法和求余数（模运算）是最慢的动作。

上面情况下和模运算相同呢？

a % b == (b-1) & a ,当b是2的指数时，等式成立。

我们说 & 与运算的定义：与运算 第一个操作数的的第n位于第二个操作数的第n位如果都是1，那么结果的第n为也为1，否则为0；

当 n 为 16 时， 与运算 101010100101001001101 时，也就是
1111 & 101010100101001001000 结果：1000 = 8
1111 & 101000101101001001001 结果：1001 = 9
1111 & 101010101101101001010 结果： 1010 = 10
1111 & 101100100111001101100 结果： 1100 = 12

可以看到，当 n 为 2 的幂次方的时候，减一之后就会得到 1111* 的数字，这个数字正好可以掩码。并且得到的结果取决于 hash 值。因为 hash 值是1，那么最终的结果也是1 ，hash 值是0，最终的结果也是0。

### HashMap 的容量为什么建议是 2的幂次方？

我们说，hash 算法的目的是为了让hash值均匀的分布在桶中（数组），那么，如何做到呢？试想一下，如果不使用 2 的幂次方作为数组的长度会怎么样？

假设我们的数组长度是10，还是上面的公式：
1010 & 101010100101001001000 结果：1000 = 8
1010 & 101000101101001001001 结果：1000 = 8
1010 & 101010101101101001010 结果： 1010 = 10
1010 & 101100100111001101100 结果： 1000 = 8

看到结果我们惊呆了，这种散列结果，会导致这些不同的key值全部进入到相同的插槽中，形成链表，性能急剧下降。

所以说，我们一定要保证 & 中的二进制位全为 1，才能最大限度的利用 hash 值，并更好的散列，只有全是1 ，才能有更多的散列结果。如果是 1010，有的散列结果是永远都不会出现的，比如 0111，0101，1111，1110…，只要 & 之前的数有 0， 对应的 1 肯定就不会出现（因为只有都是1才会为1）。大大限制了散列的范围。

### 我们自定义 HashMap 容量最好是多少？

那我们如何自定义呢？自从有了阿里的规约插件，每次楼主都要初始化容量，如果我们预计我们的散列表中有2个数据，那么我就初始化容量为2嘛？

绝对不行，如果大家看过源码就会发现，如果Map中已有数据的容量达到了初始容量的 75%，那么散列表就会扩容，而扩容将会重新将所有的数据重新散列，性能损失严重，所以，我们可以必须要大于我们预计数据量的 1.34 倍，如果是2个数据的话，就需要初始化 2.68 个容量。当然这是开玩笑的，2.68 不可以，3 可不可以呢？肯定也是不可以的，我前面说了，如果不是2的幂次方，散列结果将会大大下降。导致出现大量链表。那么我可以将初始化容量设置为4。 当然了，如果你预计大概会插入 12 条数据的话，那么初始容量为16简直是完美，一点不浪费，而且也不会扩容。

concurrenthashmap



## Hashtable

Hashtable同样是基于哈希表实现的，同样每个元素是一个key-value对，其内部也是通过单链表解决冲突问题，容量不足（超过了阀值）时，同样会自动增长。

​      Hashtable也是JDK1.0引入的类，是**线程安全**的，能用于多线程环境中。

​      Hashtable同样实现了Serializable接口，它支持序列化，实现了Cloneable接口，能被克隆。

Hashtable 中的方法是Synchronize的，而HashMap中的方法在缺省情况下是非Synchronize的。在多线程并发的环境下，可以直接使用Hashtable，不需要自己为它的方法实现同步，但使用HashMap时就必须要自己增加同步处理。（结构上的修改是指添加或删除一个或多个映射关系的任何操作；仅改变与实例已经包含的键关联的值不是结构上的修改。）这一般通过对自然封装该映射的对象进行同步操作来完成。如果不存在这样的对象，则应该使用 [Collections.synchronizedMap](http://write.blog.csdn.net/postedit/51556314#synchronizedMap(java.util.Map)) 方法来“包装”该映射。最好在创建时完成这一操作，以防止对映射进行意外的非同步访问，如下所示：

​      Map m = Collections.synchronizedMap(new HashMap(...));

​      Hashtable 线程安全很好理解，因为它每个方法中都加入了Synchronize。这里我们分析一下HashMap为什么是线程不安全的：

​      HashMap底层是一个Entry数组，当发生hash冲突的时候，hashmap是采用链表的方式来解决的，在对应的数组位置存放链表的头结点。对链表而言，新加入的节点会从头结点加入。

在hashmap做put操作的时候会调用到以上的方法。现在假如A线程和B线程同时对同一个数组位置调用addEntry，两个线程会同时得到现在的头结点，然后A写入新的头结点之后，B也写入新的头结点，那B的写入操作就会覆盖A的写入操作造成A的写入操作丢失



### key和value是否允许null值

 其中key和value都是对象，并且不能包含重复key，但可以包含重复的value。

通过上面的ContainsKey方法和ContainsValue的源码我们可以很明显的看出：

**Hashtable中，key和value都不允许出现null值**。但。是如果在Hashtable中有类似put(null,null)的操作，编译同样可以通过，因为key和value都是Object类型，但运行时会抛出NullPointerException异常，这是JDK的规范规定的。

**HashMap中，null可以作为键，这样的键只有一个**；**可以有一个或多个键所对应的值为null**。当get()方法返回null值时，可能是 HashMap中没有该键，也可能使该键所对应的值为null。因此，在HashMap中不能由get()方法来判断HashMap中是否存在某个键， 而应该用containsKey()方法来判断。

### hash值不同

哈希值的使用不同，HashTable直接使用对象的hashCode。而HashMap重新计算hash值。

hashCode是jdk根据对象的地址或者字符串或者数字算出来的int类型的数值。

Hashtable计算hash值，直接用key的hashCode()，而HashMap重新计算了key的hash值，Hashtable在求hash值对应的位置索引时，用取模运算，而HashMap在求位置索引时，则用与运算，且这里一般先用hash&0x7FFFFFFF后，再对length取模，&0x7FFFFFFF的目的是为了将负的hash值转化为正值，因为hash值有可能为负数，而&0x7FFFFFFF后，只有符号外改变，而后面的位都不变。

### 内部实现使用的数组初始化和扩容方式不同

HashTable在不指定容量的情况下的默认容量为11，而HashMap为16，Hashtable不要求底层数组的容量一定要为2的整数次幂，而HashMap则要求一定为2的整数次幂。

Hashtable和HashMap它们两个内部实现方式的数组的初始大小和扩容的方式。HashTable中hash数组默认大小是11，增加的方式是 old*2+1。

## Java虚拟机

### 类加载机制

虚拟机把描述类的数据从 Class 文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的 Java 类型，这就是虚拟机类加载机制。（类是在运行期间动态加载的）

**懒加载**：要用的时候再去加载

类的生命周期，包括以下 7 个阶段：

- **加载（Loading）**
- **验证（Verification）**
- **准备（Preparation）**
- **解析（Resolution）**
- **初始化（Initialization）**
- 使用（Using）
- 卸载（Unloading）

其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持 Java 的动态绑定。

这 7 个阶段中的：加载、验证、准备、初始化、卸载的顺序是固定的。但它们并不一定是严格同步串行执行，它们之间可能会有交叉，但总是以 “开始” 的顺序总是按部就班的。至于解析则有可能在初始化之后才开始，这是为了支持 Java 语言的运行时绑定（也称为动态绑定或晚期绑定）。

### 类加载器

虚拟机设计团队把类加载阶段中的 “通过一个类的全限定名来获取描述此类的二进制字节流（即字节码）” 这个动作放到 Java 虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类（通过一个类的全限之名获取描述此类的二进制字节流）。实现这个动作的代码模块称为 **“类加载器”**。

#### 1. 类与类加载器

两个类相等：只有被同一个类加载器加载的类才可能会相等。相同的字节码被不同的类加载器加载的类不相等。

这里的相等，包括类的 Class 对象的 equals() 方法、isAssignableFrom() 方法、isInstance() 方法的返回结果为 true，也包括使用 instanceof 关键字做对象所属关系判定结果为 true。

#### 2. 类加载器分类

从 Java 虚拟机的角度来讲，只存在以下两种不同的类加载器：

- **启动类加载器**（Bootstrap ClassLoader），这个类加载器用 C++ 实现，是虚拟机自身的一部分；
- **所有其他类的加载器**，这些类由 Java 实现，独立于虚拟机外部，并且全都继承自抽象类 java.lang.ClassLoader。

从 Java 开发人员的角度看，类加载器可以划分得更细致一些：

- <font size=3 font color=#228B22 font face="黑体">**启动类加载器**</font>

  （Bootstrap ClassLoader）

  - 此类加载器负责将存放在 <JAVA_HOME>\lib 目录中的，或者被 -Xbootclasspath 参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如 rt.jar，名字不符合的类库即使放在 lib 目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被 Java 程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给启动类加载器，直接使用 null 代替即可。

- <font size=3 font color=#228B22 font face="黑体">**扩展类加载器**</font>

  （Extension ClassLoader）

  - 这个类加载器是由 ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将 <JAVA_HOME>/lib/ext 或者被 java.ext.dir 系统变量所指定路径中的所有类库加载到内存中，开发者可以直接使用扩展类加载器。

- <font size=3 font color=#228B22 font face="黑体">**应用程序类加载器**</font>

  （Application ClassLoader）

  - 这个类加载器是由 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。由于这个类加载器是 ClassLoader 中的 getSystemClassLoader() 方法的返回值，因此一般称为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。
  
  ![image-20191103194747924](/Users/ss/Documents/面试/类加载.png)


自定义类加载器

- 步骤：
  - 定义一个类，继承 ClassLoader
  - 重写 loadClass 方法
  - 实例化 Class 对象
- 自定义类加载器的优势
  - 类加载器是 Java 语言的一项创新，也是 Java 语言流行的重要原因之一，它最初的设计是为了满足 java applet 的需求而开发出来的
  - 高度的灵活性
  - 通过自定义类加载器可以实现热部署
  - 代码加密

#### 3. 双亲委派模型

- 为什么要使用双亲委派模型？
  - 主要是为了避免重复加载的问题
- 这种设计有个好处是，如果有人想替换系统级别的类：String.java。篡改它的实现，但是在这种机制下这些系统的类已经被Bootstrap classLoader加载过了，所以并不会再去加载，从一定程度上防止了危险代码的植入
  
- JVM 如何加载一个类的过程，双亲委派模型中有哪些方法有没有可能父类加载器和子类加载器，加载同一个类？如果加载同一个类，该使用哪一个类？
  * 父类的

- **双亲委派概念**
  * 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的加载器都是如此，因此所有的类加载请求都会传给顶层的启动类加载器，只有当父加载器反馈自己无法完成该加载请求（该加载器的搜索范围中没有找到对应的类）时，子加载器才会尝试自己去加载。

### 虚拟机栈存放内容

每个方法在执行的同时都会创建一个栈帧(Stack Frame)用于存储**局部变量表、操作数栈、动态链接、方法出口**等信息。

每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程

### 本地方法栈

每个java方法在执行时，会创建一个“栈帧（stack frame）”，栈帧的结构分为“局部变量表、操作数栈、动态链接、方法出口”几个部分（具体的作用会在字节码执行引擎章节中讲到，这里只需要了解栈帧是一个方法执行时所需要数据的结构）。我们常说的“堆内存、栈内存”中的“栈内存”指的便是虚拟机栈，确切地说，指的是虚拟机栈的栈帧中的局部变量表，因为这里存放了一个方法的所有局部变量。

方法调用时，创建栈帧，并压入虚拟机栈；方法执行完毕，栈帧出栈并被销毁

**本地方法栈的功能和特点类似于虚拟机栈**，均具有线程隔离的特点以及都能抛出StackOverflowError和OutOfMemoryError异常。

不同的是，本地方法栈服务的对象是JVM执行的**native方法**，而虚拟机栈服务的是JVM执行的java方法。

一. 什么是Native Method
   简单地讲，一个Native Method就是一个java**调用非java代码的接口**。一个Native Method是这样一个java的方法：该方法的实现由非java语言实现，比如C。这个特征并非java所特有，很多其它的编程语言都有这一机制，比如在C＋＋中，你可以用extern "C"告知C＋＋编译器去调用一个C的函数。

二.为什么要使用Native Method
   java使用起来非常方便，然而有些层次的任务用java实现起来不容易，或者我们对程序的效率很在意时，问题就来了。
   与java环境外交互：
   有时java应用需要与java外面的环境交互。这是本地方法存在的主要原因，你可以想想java需要与一些底层系统如操作系统或某些硬件交换信息时的情况。本地方法正是这样一种交流机制：它为我们提供了一个非常简洁的接口，而且我们无需去了解java应用之外的繁琐的细节。
   与操作系统交互：
   JVM支持着java语言本身和运行时库，它是java程序赖以生存的平台，它由一个解释器（解释字节码）和一些连接到本地代码的库组成。然而不管怎 样，它毕竟不是一个完整的系统，它经常依赖于一些底层（underneath在下面的）系统的支持。这些底层系统常常是强大的操作系统。通过使用本地方法，我们得以用java实现了jre的与底层系统的交互，甚至JVM的一些部分就是用C写的，还有，如果我们要使用一些java语言本身没有提供封装的操作系统的特性时，我们也需要使用本地方法。
    Sun's Java
    Sun的解释器是用C实现的，这使得它能像一些普通的C一样与外部交互。jre大部分是用java实现的，它也通过一些本地方法与外界交互。例如：类java.lang.Thread 的 setPriority()方法是用java实现的，但是它实现调用的是该类里的本地方法setPriority0()。这个本地方法是用C实现的，并被植入JVM内部，在Windows 95的平台上，这个本地方法最终将调用Win32 SetPriority() API。这是一个本地方法的具体实现由JVM直接提供，更多的情况是本地方法由外部的动态链接库（external dynamic link library）提供，然后被JVM调用。

三. JVM怎样使Native Method跑起来：

 我们知道，当一个类第一次被使用到时，这个类的字节码会被加载到内存，并且只会回载一次。在这个被加载的字节码的入口维持着一个该类所有方法描述符的list，这些方法描述符包含这样一些信息：方法代码存于何处，它有哪些参数，方法的描述符（public之类）等等。
    如果一个方法描述符内有native，这个描述符块将有一个指向该方法的实现的指针。这些实现在一些DLL文件内，但是它们会被操作系统加载到java程序的地址空间。当一个带有本地方法的类被加载时，其相关的DLL并未被加载，因此指向方法实现的指针并不会被设置。当本地方法被调用之前，这些DLL才会被加载，这是通过调用java.system.loadLibrary()实现的。

   最后需要提示的是，使用本地方法是有开销的，它丧失了java的很多好处。如果别无选择，我们可以选择使用本地方法。

### 垃圾回收

#### GCroot

##### GC用的引用可达性分析算法中，哪些对象可作为GC Roots对象？

- 虚拟机栈（栈帧中的本地变量表）中引用的对象。
- 方法区中静态属性引用的对象。
- 方法区中常量引用的对象。
- 本地方法栈中 JNI （即一般说的 Native 方法）引用的对象。

####垃圾回收算法

标记-清理

标记-整理

复制

#### CMS

![image-20190507193147013](/Users/ss/Library/Application Support/typora-user-images/image-20190507193147013.png)

CMS（Concurrent Mark Sweep），Mark Sweep 指的是 **标记 - 清除** 算法。CMS 是一款优秀的收集器，主要优点：并发收集、低停顿，Sun公司也称之为**并发低停顿收集器**（Concurrent Low Pause Collection）。

分为以下四个流程：

- 初始标记：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。
- **并发标记**：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。
- 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。
- **并发清除**：不需要停顿。

#### G1

G1 把堆划分成多个大小相等的独立区域（Region），新生代和老年代不再物理隔离。

通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。

每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。

![image-20190507195725425](/Users/ss/Documents/面试/G！.png)

- 初始标记
- 并发标记
- 最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。
- 筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。

具备如下特点：

- 空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。
- 可预测的停顿：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。

从官网的描述中，我们知道G1是一种服务器端的垃圾收集器，应用在多处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能的满足垃圾收集暂停时间的要求。它是专门针对以下应用场景设计的: 

- 像CMS收集器一样，能与应用程序线程并发执行。 
- 整理空闲空间更快。 
- 需要GC停顿时间更好预测。 
- 不希望牺牲大量的吞吐性能。 
- 不需要更大的Java Heap。

G1收集器的设计目标是取代CMS收集器，它同CMS相比，在以下方面表现的更出色： 

G1是一个有整理内存过程的垃圾收集器，不会产生很多内存碎片。 

G1的Stop The World(STW)更可控，G1在停顿时间上添加了预测机制，用户可以指定期望停顿时间。

| 收集器                | 单线程/并行 | 串行/并发 | 新生代/老年代   | 收集算法             | 目标         | 适用场景                                      |
| --------------------- | ----------- | --------- | --------------- | -------------------- | ------------ | --------------------------------------------- |
| **Serial**            | 单线程      | 串行      | 新生代          | 复制                 | 响应速度优先 | 单 CPU 环境下的 Client 模式                   |
| **ParNew**            | 并行        | 串行      | 新生代          | 复制                 | 响应速度优先 | 多 CPU 环境时在 Server 模式下与 CMS 配合      |
| **Parallel Scavenge** | 并行        | 串行      | 新生代          | 复制                 | 吞吐量优先   | 在后台运算而不需要太多交互的任务              |
| **Serial Old**        | 单线程      | 串行      | 老年代          | 标记-整理            | 响应速度优先 | 单 CPU 环境下的 Client 模式、CMS 的后备预案   |
| **Parallel Old**      | 并行        | 串行      | 老年代          | 标记-整理            | 吞吐量优先   | 在后台运算而不需要太多交互的任务              |
| **CMS**               | 并行        | 并发      | 老年代          | 标记-清除            | 响应速度优先 | 集中在互联网站或 B/S 系统服务端上的 Java 应用 |
| **G1**                | 并行        | 并发      | 新生代 + 老年代 | 标记-整理 + 复制算法 | 响应速度优先 | 面向服务端应用，将来替换 CMS                  |

#### 内存分配策略

1. **对象优先在 Eden 分配**

大多数情况下，对象在新生代 Eden 区分配，当 Eden 区空间不够时，发起 Minor GC。

2. **大对象直接进入老年代**

大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。

经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。

-XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 区和 Survivor 区之间的大量内存复制。

3. **长期存活的对象进入老年代**

为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。默认是**15**。

-XX:MaxTenuringThreshold 用来定义年龄的阈值。

4. **动态对象年龄判定**

虚拟机并不是永远地要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。

5. **空间分配担保**

在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。

如果不成立的话虚拟机会查看 HandlePromotionFailure 设置值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 设置不允许冒险，那么就要进行一次 Full GC。

# 二、算法

## 算法题

1. ### 查找数组中重复数据

2. ### 求众数

3. ### 最长连续子串

4. ### dp

5. ### 最大连续子序列和

6. ### 链表去重

7. ### 数组去重

8. ### 链表反转

9. ### 快速排序

   快速排序的一次划分算法从两头交替搜索，直到low和high重合，因此其时间复杂度是O(n)；而整个快速排序算法的时间复杂度与划分的趟数有关。 

   理想的情况是，每次划分所选择的中间数恰好将当前序列几乎等分，经过log2n趟划分，便可得到长度为1的子表。这样，整个算法的时间复杂度为O(nlog2n)。 

   最坏的情况是，每次所选的中间数是当前序列中的最大或最小元素，这使得每次划分所得的子表中一个为空表，另一子表的长度为原表的长度-1。这样，长度为n的数据表的快速排序需要经过n趟划分，使得整个排序算法的时间复杂度为O(n2)。

   从空间性能上看，尽管快速排序只需要一个元素的辅助空间，但快速排序需要一个**栈空间来实现递归**。最好的情况下，即快速排序的每一趟排序都将元素序列均匀地分割成长度相近的两个子表，所需栈的最大深度为log2(n+1)；但最坏的情况下，栈的最大深度为n。这样，快速排序的空间复杂度为O(log2n))。

   划分方法：

   ```java
   /**
   * 快速排序--辅助方法
   * 将原数组划分成为两个部分 使得左面的都小于某个数 右面的都大于某个数
   */
   public static int partition(int[] a, int left, int right) {
       int num = a[left]; //使用第一个元素作为划分依据元素
       while(left < right) {
           //完成划分过程 使得左面的都小于某个数 右面的都大于某个数
           while(a[right] > num) 
               right--;
           a[left] = a[right];
           
           while((left<right) && a[left]<num) 
               left++;
           a[right] = a[left];
       }
       a[left] = num;
       return left;
   }
   ```

   递归调用：

   ```java
   /**
   * 快速排序
   */
   public static void quickSort(int[] a, int left, int right) {
       if(left < right) {
           int n = partition(a, left, right);
           quickSort(a, left, n-1);
           quickSort(a, n+1, right);
       }
   }
   ```

## 各种排序算法的比较

| 算法名称 | 最坏时间                                                     | 平均时间                                                     | 空间   | 稳定性                                                       | 初始顺序 |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------ | ------------------------------------------------------------ | -------- |
| 冒泡     | n^2                                                          | n^2                                                          | 1      | 稳定                                                         |          |
| 选择     | n^2                                                          | n^2                                                          | 1      | <font size=3 font color=#6A5ACD font face="黑体">**不稳定**</font> |          |
| 插入     | n^2                                                          | n^2                                                          | 1      | 稳定                                                         |          |
| 桶       | n^2                                                          | n                                                            | n      | 稳定                                                         |          |
| 基数     | D*n                                                          | D*n                                                          | D*n    | 稳定                                                         |          |
| 希尔     | n^2                                                          | n^1.3                                                        | 1      | <font size=3 font color=#6A5ACD font face="黑体">**不稳定**</font> |          |
| 快速     | <font size=3 font color=#B22222 font face="黑体">**n^2**</font> | <font size=3 font color=#B22222 font face="黑体">**nlog(n)**</font> | log(n) | <font size=3 font color=#6A5ACD font face="黑体">**不稳定**</font> |          |
| 归并     | <font size=3 font color=#B22222 font face="黑体">**nlog(n)**</font> | <font size=3 font color=#B22222 font face="黑体">**nlog(n)**</font> | n      | 稳定                                                         |          |
| 堆       | nlog(n)                                                      | nlog(n)                                                      | 1      | <font size=3 font color=#6A5ACD font face="黑体">**不稳定**</font> |          |

1.元素的**移动次数**与关键字的初始排列次序无关的是：基数排序。

2.元素的**比较次数**与初始序列无关是：选择排序。

​      解释：选择排序每一趟都从待排序的数据元素中选出最小的或者最大的一个元素。

3.算法的**时间复杂度**与初始序列无关的是：直接选择排序。

## 为什么快速排序要比堆排序性能好？

第一、堆排序访问数据的方式没有快速排序友好。

对于快速排序来说，数据是顺序访问的。而对于堆排序来说，数据是跳着访问的。比如，堆排序中，最重要的一个操作就是数据的堆化。比如下面这个例子，对堆顶进行堆化，会依次访问数组下标是1，2，4，8的元素，而不像快速排序那样，局部顺序访问，所以，这样对CPU缓存是不友好的。

第二、对于同样的数据，在排序过程中，堆排序算法的数据交换次数要多于快速排序。

对于基于比较的排序算法来说，整个排序过程是由两个基本操作组成的，比较和交换。快速排序交换的次数不会比逆序度多。但是堆排序的第一步是建堆，建堆的过程会打乱数据原有的相对选择顺序，导致数据有序度降低。比如对于一组已经有序的数据来说，经过建堆之后，数据反而变得更无序了。

## 查找

1. 顺序（**O(n)**）

2. 二分<font size=3 font color=#DA70D6 font face="黑体">（**O(log2n)**）</font>（是以2为底，n的对数）

   总共有n个元素，

   渐渐跟下去就是n,n/2,n/4,....n/2^k（接下来操作元素的剩余个数），其中k就是循环的次数

   由于你n/2^k取整后>=1

   即令n/2^k=1

   可得k=log2n,（是以2为底，n的对数）

3. 插值查找：基于二分查找算法，将查找点的选择改进为自适应选择，可以提高查找效率。当然，差值查找也属于有序查找。

注：**对于表长较大，而关键字分布又比较均匀的查找表来说，插值查找算法的平均性能比折半查找要好的多。反之，数组中如果分布非常不均匀，那么插值查找未必是很合适的选择。**

　　**复杂度分析：查找成功或者失败的时间复杂度均为O(log2(log2n))。**

4.  斐波那契查找：也是二分查找的一种提升算法，通过运用黄金比例的概念在数列中选择查找点进行查找，提高查找效率。同样地，斐波那契查找也属于一种有序查找算法。

5. 树

   - 查找树（**O(log2n)**）

   它和二分查找一样，插入和查找的时间复杂度均为**O(logn)**，但是在**最坏的情况下仍然会有O(n)**的时间复杂度。原因在于插入和删除元素的时候，树没有保持平衡。

   - 平衡树（**O(log2n)**）

   - 红黑树

     **红黑树的操作**

     因为每一个红黑树也是一个特化的二叉查找树，因此红黑树上的查找操作与普通二叉查找树上的查找操作相同。然而，在红黑树上进行插入操作和删除操作会导致不 再符合红黑树的性质。恢复红黑树的属性需要少量(O(log n))的颜色变更(实际是非常快速的)和不超过三次树旋转(对于插入操作是两次)。 虽然插入和删除很复杂，但操作时间仍可以保持为 O(log n) 次 。

     **红黑树的优势**

     红黑树能够以O(log2(N))的时间复杂度进行搜索、插入、删除操作。此外,任何不平衡都会在**3次旋转之内**解决。这一点是AVL所不具备的。

   - B/B+树

     **B和B+树的区别在于，B+树的非叶子结点只包含导航信息，不包含实际的值，所有的叶子结点和相连的节点使用链表相连，便于区间查找和遍历。**

     　B+ 树的优点在于：

     - 由于B+树在内部节点上不好含数据信息，因此在内存页中能够存放更多的key。 数据存放的更加紧密，具有更好的空间局部性。因此访问叶子几点上关联的数据也具有更好的缓存命中率。
     - B+树的叶子结点都是相链的，因此对整棵树的遍历只需要一次线性遍历叶子结点即可。而且由于数据顺序排列并且相连，所以便于区间查找和搜索。而B树则需要进行每一层的递归遍历。相邻的元素可能在内存中不相邻，所以缓存命中性没有B+树好。

     　　**但是B树也有优点，其优点在于，由于B树的每一个节点都包含key和value，因此经常访问的元素可能离根节点更近，因此访问也更迅速。**

二叉查找树平均查找性能不错，为O(logn)，但是最坏情况会退化为O(n)。在二叉查找树的基础上进行优化，我们可以使用平衡查找树。平衡查找树中的2-3查找树，这种数据结构在插入之后能够进行自平衡操作，从而保证了树的高度在一定的范围内进而能够保证最坏情况下的时间复杂度。但是2-3查找树实现起来比较困难，红黑树是2-3树的一种简单高效的实现，他巧妙地使用颜色标记来替代2-3树中比较难处理的3-node节点问题。红黑树是一种比较高效的平衡查找树，应用非常广泛，很多编程语言的内部实现都或多或少的采用了红黑树。

除此之外，2-3查找树的另一个扩展——B/B+平衡树，在文件系统和数据库系统中有着广泛的应用

6. 分块查找

   分块查找又称索引顺序查找，它是顺序查找的一种改进方法。
   　　**算法思想：**将n个数据元素"按块有序"划分为m块（m ≤ n）。每一块中的结点不必有序，但块与块之间必须"按块有序"；即第1块中任一元素的关键字都必须小于第2块中任一元素的关键字；而第2块中任一元素又都必须小于第3块中的任一元素，……

7. 哈希

　　**算法思想：**哈希的思路很简单，如果所有的键都是整数，那么就可以使用一个简单的无序数组来实现：将键作为索引，值即为其对应的值，这样就可以快速访问任意键的值。这是对于简单的键的情况，我们将其扩展到可以处理更加复杂的类型的键。

　　**算法流程：**

　　1）用给定的哈希函数构造哈希表；

　　2）根据选择的冲突处理方法解决地址冲突；

　　　　常见的解决冲突的方法：拉链法和线性探测法。

　　3）在哈希表的基础上执行哈希查找。

　　**哈希表是一个在时间和空间上做出权衡的经典例子。如果没有内存限制，那么可以直接将键作为数组的索引。那么所有的查找时间复杂度为O(1)；如果没有时间限制，那么我们可以使用无序数组并进行顺序查找，这样只需要很少的内存。哈希表使用了适度的时间和空间来在这两个极端之间找到了平衡。只需要调整哈希函数算法即可在时间和空间上做出取舍。**

　　**复杂度分析**：

　　单纯论查找复杂度：对于无冲突的Hash表而言，查找复杂度为O(1)（注意，在查找之前我们需要构建相应的Hash表）。

## 深度遍历

由初始顶点开始,沿着一条道一直走,当走到走不动的时候,再回来走一条可以走的通的道,然后再继续往下走,直到走不动,再回来

## 广度遍历

广度遍历我觉得理解起来更简单,就是一层一层的进行遍历,

和二叉树的层序遍历一样,图的广度遍历也用到了队列,对于下图而言,先将0放入队首----->然后遍历0并将0从队列中取出,同时将0的邻接点1,3,4入队,这样队首就是1----->然后将1出队,并将1的邻接点入队(这里只有5), 这样队首就是3----->然后将3弹出并将3的邻接点入队(这里没有),这样队首就是4----->然后将4弹出并将4的邻接点入队(这里没有),队首就是从1入队的1的第一个邻接点(这里是5)---->然后将5弹出----->直到队列为空这样就完成了由定点0开始的广度优先遍历

# 三、数据库

### 主键

表通常具有包含唯一标识表中每一行的值的一列或一组列。这样的一列或多列称为表的主键 (PK)，用于强制表的实体完整性。在创建或修改表时，您可以通过定义 PRIMARY KEY 约束来创建主键。

一个表只能有一个 PRIMARY KEY 约束，并且 PRIMARY KEY 约束中的列不能接受空值。由于 PRIMARY KEY 约束可保证数据的唯一性，因此经常对标识列定义这种约束。

### 数据库锁

一般可以分为两类，一个是悲观锁，一个是乐观锁，悲观锁一般就是我们通常说的数据库锁机制，乐观锁一般是指用户自己实现的一种锁机制，比如hibernate实现的乐观锁甚至编程语言也有乐观锁的思想的应用。

#### 悲观锁

按使用性质划分

- **共享锁（Share locks简记为S锁）**：也称**读锁**，事务A对对象T加S锁，其他事务也只能对T加S，多个事务可以同时读，但不能有写操作，直到A释放S锁。
- **排它锁（Exclusivelocks简记为X锁）**：也称写锁，事务A对对象T加X锁以后，其他事务不能对T加任何锁，只有事务A可以读写对象T直到A释放X锁。
- **更新锁（简记为U锁）**：用来预定要对此对象施加X锁，它允许其他事务读，但不允许再施加U锁或X锁；当被读取的对象将要被更新时，则升级为X锁，主要是用来防止死锁的。因为使用共享锁时，修改数据的操作分为两步，首先获得一个共享锁，读取数据，然后将共享锁升级为排它锁，然后再执行修改操作。这样如果同时有两个或多个事务同时对一个对象申请了共享锁，在修改数据的时候，这些事务都要将共享锁升级为排它锁。这些事务都不会释放共享锁而是一直等待对方释放，这样就造成了死锁。如果一个数据在修改前直接申请更新锁，在数据修改的时候再升级为排它锁，就可以避免死锁。

### 事务管理ACID

**原子性**（Atomicity）

原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。

**一致性**（Consistency）

事务前后数据的完整性必须保持一致。

**隔离性**（Isolation）

事务的隔离性是多个用户并发访问数据库时，数据库为每一个用户开启的事务，不能被其他事务的操作数据所干扰，多个并发事务之间要相互隔离。

**持久性**（Durability）

持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响

**脏读**：

指一个事务读取了另外一个事务未提交的数据

**不可重复读**：
在一个事务内读取表中的某一行数据，多次读取结果不同。（这个不一定是错误，只是某些场合不对）

**虚读(幻读)**

是指在一个事务内读取到了别的事务插入的数据，导致前后读取不一致。
（一般是行影响，多了一行）

Serializable		可避免脏读、不可重复读、虚读情况的发生。（串行化）

Repeatable read	可避免脏读、不可重复读情况的发生。（可重复读）

Read committed	可避免脏读情况发生（读已提交）。

Read uncommitted	最低级别，以上情况均无法保证。(读未提交)

**在MySQL数据库中，支持上面四种隔离级别，默认的为Repeatable read (可重复读)；而在Oracle数据库中，只支持Serializable (串行化)级别和Read committed (读已提交)这两种级别，其中默认的为Read committed级别。**

### 索引

建立索引的目的是加快对表中记录的查找或排序。为表设置索引要付出代价的：一是增加了数据库的存储空间，二是在插入和修改数据时要花费较多的时间(因为索引也要随之变动)。数据库索引就是为了提高表的搜索效率而对某些字段中的值建立的目录 。

#### MyISAM存储引擎

MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址（叶节点data域）。

主键索引：B+ Tree的叶子节点的key存放主键值，data存放主键值对应数据行的存储地址，而非叶子节点key为主键值，不存储data。查找时通过key从上往下找到叶子结点，如果key存在，拿到数据行存储地址。

<img src="/Users/ss/Library/Application Support/typora-user-images/image-20191103205430140.png" alt="image-20191103205430140" style="zoom:50%;" />

辅助索引(secondary key)：上图中col1为主键，在col2上建立一个辅助索引，其结构如下，可以发现其结构和主键索引没有区别，叶子节点data存放的也是数据行地址（不同之处在于主索引要求key是唯一的，而辅助索引的key可以重复）

![img](https://img2018.cnblogs.com/blog/1483773/201904/1483773-20190421162257552-17831722.png)

#### **InnoDB存储引擎**

InnoDB的数据文件本身就是索引文件，叶节点data域保存了完整的数据记录

主键索引：其结构如下，B+ Tree的叶子节点key存放主键值，data存放完整的数据记录。非叶子节点key为主键值，不存储data。查找时通过key从上往下找到叶子结点，如果key存在，直接拿到数据。

![img](https://img2018.cnblogs.com/blog/1483773/201904/1483773-20190421162326523-1475174136.png)

辅助索引：对于辅助索引的结构如下，与主键索引不同的是，叶节点的data存放存放主键索引的值，而不是地址，因此辅助索引进行检索时需要检索两遍索引,首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。

![img](https://img2018.cnblogs.com/blog/1483773/201904/1483773-20190421162403549-594411706.png)

通过上述结构发现，InnoDB数据文件即包含主键索引，所以InnoDB要求表必须有主键，如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键。而且不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。另外，用非单调的字段作为主键在InnoDB中也不建议，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。



n是记录总树，底数是树的分叉数，结果就是树的层次数。换言之，查找次数是以树的分叉数为底，记录总数的对数，用公式来表示就是

![image-20190511182223376](/Users/ss/Documents/面试/索引时间复杂度.png)

用程序来表示就是Math.Log(100000000,10)，100000000是记录数，10是树的分叉数（真实环境下分叉数远不止10）， 结果就是查找次数，这里的结果从亿降到了个位数。因此，利用索引会使数据库查询有惊人的性能提升。

然而， 事物都是有两面的， 索引能让数据库查询数据的速度上升， 而使写入数据的速度下降，原因很简单的， 因为平衡树这个结构必须一直维持在一个正确的状态， 增删改数据都会改变平衡树各节点中的索引数据内容，破坏树结构， 因此，在每次数据改变时， DBMS必须去重新梳理树（索引）的结构以确保它的正确，这会带来不小的性能开销，也就是为什么索引会给查询以外的操作带来副作用的原因。

##### 2、非聚集索引

非聚集索引和聚集索引的区别在于， 通过聚集索引可以查到需要查找的数据， 而通过非聚集索引可以查到记录对应的主键值 ， 再使用主键的值通过聚集索引查找到需要的数据。

![image-20190511183658738](/Users/ss/Documents/面试/非聚集索引.png)

不管以任何方式查询表， 最终都会利用主键通过聚集索引来定位到数据， 聚集索引（主键）是通往真实数据所在的唯一路径。

#### 3、覆盖索引

然而， 有一种例外可以不使用聚集索引就能查询出所需要的数据， 这种非主流的方法 称之为「覆盖索引」查询， 也就是平时所说的复合索引或者多字段索引查询。 文章上面的内容已经指出， 当为字段建立索引以后， 字段中的内容会被同步到索引之中， 如果为一个索引指定两个字段， 那么这个两个字段的内容都会被同步至索引之中。

#### 举例：

先看下面这个SQL语句

//建立索引

create index index_birthday on user_info(birthday);

//查询生日在1991年11月1日出生用户的用户名

select user_name from user_info where birthday = '1991-11-1'

这句SQL语句的执行过程如下

首先，通过非聚集索引index_birthday查找birthday等于1991-11-1的所有记录的主键ID值

然后，通过得到的主键ID值执行聚集索引查找，找到主键ID值对就的真实数据（数据行）存储的位置

最后， 从得到的真实数据中取得user_name字段的值返回， 也就是取得最终的结果

我们把birthday字段上的索引改成双字段的覆盖索引

create index index_birthday_and_user_name on user_info(birthday, user_name);

这句SQL语句的执行过程就会变为

通过非聚集索引index_birthday_and_user_name查找birthday等于1991-11-1的叶节点的内容，然而， 叶节点中除了有user_name表主键ID的值以外， user_name字段的值也在里面， 因此不需要通过主键ID值的查找数据行的真实所在， 直接取得叶节点中user_name的值返回即可。 通过这种覆盖索引直接查找的方式， 可以省略不使用覆盖索引查找的后面两个步骤， 大大的提高了查询性能。

### 优化Mysql数据库的8个方法

本文通过8个方法优化Mysql数据库：创建索引、复合索引、索引不会包含有NULL值的列、使用短索引、排序的索引问题、like语句操作、不要在列上进行运算、不使用NOT IN和<>操作

**1、创建索引**
对于查询占主要的应用来说，索引显得尤为重要。很多时候性能问题很简单的就是因为我们忘了添加索引而造成的，或者说没有添加更为有效的索引导致。如果不加索引的话，那么查找任何哪怕只是一条特定的数据都会进行一次全表扫描，如果一张表的数据量很大而符合条件的结果又很少，那么不加索引会引起致命的性能下降。但是也不是什么情况都非得建索引不可，比如性别可能就只有两个值，建索引不仅没什么优势，还会影响到更新速度，这被称为过度索引。
**2、复合索引**
比如有一条语句是这样的：select * from users where area='beijing' and age=22;
如果我们是在area和age上分别创建单个索引的话，由于mysql查询每次只能使用一个索引，所以虽然这样已经相对不做索引时全表扫描提高了很多效率，但是如果在area、age两列上创建复合索引的话将带来更高的效率。如果我们创建了(area, age, salary)的复合索引，那么其实相当于创建了(area,age,salary)、(area,age)、(area)三个索引，这被称为最佳左前缀特性。因此我们在创建复合索引时应该将最常用作限制条件的列放在最左边，依次递减。
**3、索引不会包含有NULL值的列**
只要列中包含有NULL值都将不会被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为NULL。
**4、使用短索引**
对串列进行索引，如果可能应该指定一个前缀长度。例如，如果有一个CHAR(255)的 列，如果在前10 个或20 个字符内，多数值是唯一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。

**5、排序的索引问题**
mysql查询只使用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作；尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引。
**6、like语句操作**
一般情况下不鼓励使用like操作，如果非使用不可，如何使用也是一个问题。like “%aaa%” 不会使用索引而like “aaa%”可以使用索引。
**7、不要在列上进行运算**
select * from users where YEAR(adddate)<2007;
将在每个行上进行运算，这将导致索引失效而进行全表扫描，因此我们可以改成
select * from users where adddate<‘2007-01-01';
**8、不使用NOT IN和<>操作**
NOT IN和<>操作都不会使用索引将进行全表扫描。NOT IN可以NOT EXISTS代替，id<>3则可使用id>3 or id<3来代替。

### 索引失效

- 如果MySQL估计使用**全表扫秒比使用索引快**，则不适用索引。

  例如，如果列key均匀分布在1和100之间，下面的查询使用索引就不是很好：select * from table_name where key>1 and key<90;

- 如果**条件中有or**，即使其中有条件带索引也不会使用

  例如：select * from table_name where key1='a' or key2='b';如果在key1上有索引而在key2上没有索引，则该查询也不会走索引

- 复合索引，如果索引列**不是复合索引的第一部分**，则不使用索引（即不符合最左前缀）

  例如，复合索引为(key1,key2),则查询select * from table_name where key2='b';将不会使用索引

- 如果**like是以 % 开始的**，则该列上的索引不会被使用。

  例如select * from table_name where key1 like '%a'；该查询即使key1上存在索引，也不会被使用如果列类型是字符串，那一定要在条件中使用引号引起来，否则不会使用索引

- 如果列为字符串，则where条件中必须将字符常量值加引号，否则即使该列上存在索引，也不会被使用。

  例如,select * from table_name where key1=1;如果key1列保存的是字符串，即使key1上有索引，也不会被使用。

- 如果使用MEMORY/HEAP表，并且where条件中不使用“=”进行索引列，那么不会用到索引，head表只有在“=”的条件下才会使用索引

### B 树相对于红黑树的区别

- **AVL 树和红黑树基本都是存储在内存中才会使用的数据结构**。在大规模数据存储的时候，红黑树往往出现由于**树的深度过大**而造成磁盘 IO 读写过于频繁，进而导致效率低下的情况。为什么会出现这样的情况，我们知道要获取磁盘上数据，必须先通过磁盘移动臂移动到数据所在的柱面，然后找到指定盘面，接着旋转盘面找到数据所在的磁道，最后对数据进行读写。磁盘IO代价主要花费在查找所需的柱面上，树的深度过大会造成磁盘IO频繁读写。根据**磁盘查找存取的次数往往由树的高度所决定**，所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度，B树可以有多个子女，从几十到上千，可以降低树的高度。
- **数据库系统的设计者巧妙利用了磁盘预读原理**，将一个节点的大小设为等于一个页，这样每个节点只需要一次 I/O 就可以完全载入。为了达到这个目的，在实际实现 B-Tree 还需要使用如下技巧：每次新建节点时，直接申请一个页的空间，这样就保证**一个节点物理上也存储在一个页里**，加之计算机存储分配都是按页对齐的，就实现了一个 node 只需一次 I/O。

### 引擎

MyISAM和InnoDB存储引擎：只支持BTREE索引， 也就是说默认使用BTREE，不能够更换

MEMORY/HEAP存储引擎：支持HASH和BTREE索引

#### **MyISAM与InnoDB的区别**

1、MyISAM：默认表类型，它是基于传统的ISAM类型，ISAM是Indexed Sequential Access Method (有索引的顺序访问方法) 的缩写，它是存储记录和文件的标准方法。不是事务安全的，而且不支持外键，如果执行大量的select，insert MyISAM比较适合。

2、InnoDB：支持事务安全的引擎，支持外键、行锁、事务是他的最大特点。如果有大量的update和insert，建议使用InnoDB，特别是针对多个并发和QPS较高的情况。

##### **1、表锁差异**

**MyISAM**:

myisam只支持**表级锁**，用户在操作myisam表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。也可以通过lock table命令来锁表，这样操作主要是可以模仿事务，但是消耗非常大，一般只在实验演示中使用。

**InnoDB ：**

Innodb支持**事务**和**行级锁**，是innodb的最大特色。

事务的ACID属性：atomicity,consistent,isolation,durable。

并发事务带来的几个问题：更新丢失，脏读，不可重复读，幻读。

事务隔离级别：未提交读(Read uncommitted)，已提交读(Read committed)，可重复读(Repeatable read)，可序列化(Serializable)



众多资料中都说innodb使用的是行级锁，但实际上是有限制的。只有在你增删改查时匹配的条件字段带有索引时，innodb才会使用行级锁，在你增删改查时匹配的条件字段不带有索引时，innodb使用的将是表级锁。因为当你匹配条件字段不带有所引时，数据库会全表查询，所以这需要将整张表加锁,才能保证查询匹配的正确性。在生产环境中我们往往需要满足多人同时对一张表进行增删改查，所以就需要使用行级锁，所以这个时候一定要记住为匹配条件字段加索引。

提到行级锁和表级锁时我们就很容易联想到读锁和写锁，因为只有触发了读写锁，我们才会谈是进行行级锁定还是进行表级锁定。那么什么时候触发读锁，就是在你用select 命令时触发读锁，什么时候触发写锁，就是在你使用update,delete,insert时触发写锁，并且使用rollback或commit后解除本次锁定。

##### 2、数据库文件差异

MyISAM ：**myisam属于堆表myisam在磁盘存储上有三个文件，每个文件名以表名开头，扩展名指出文件类型。**

.frm 用于存储表的定义

.MYD 用于存放数据.MYI 用于存放表索引myisam表还支持三种不同的存储格式：静态表(默认，但是注意数据末尾不能有空格，会被去掉)动态表压缩表

InnoDB ：innodb属于索引组织表

innodb有两种存储方式，共享表空间存储和多表空间存储

两种存储方式的表结构和myisam一样，以表名开头，扩展名是.frm。

如果使用共享表空间，那么所有表的数据文件和索引文件都保存在一个表空间里，一个表空间可以有多个文件，通过innodb_data_file_path和innodb_data_home_dir参数设置共享表空间的位置和名字，一般共享表空间的名字叫ibdata1-n。

如果使用多表空间，那么每个表都有一个表空间文件用于存储每个表的数据和索引，文件名以表名开头，以.ibd为扩展名。 

**三、索引差异**

1、关于自动增长

myisam引擎的自动增长列必须是索引，如果是组合索引，自动增长可以不是第一列，他可以根据前面几列进行排序后递增。

innodb引擎的自动增长列必须是索引，如果是组合索引也必须是组合索引的第一列。

2、关于主键

myisam允许没有任何索引和主键的表存在，

myisam的索引都是保存行的地址。

innodb引擎如果没有设定主键或者非空唯一索引，就会自动生成一个6字节的主键(用户不可见)

innodb的数据是主索引的一部分，附加索引保存的是主索引的值。

3、关于count()函数

myisam保存有表的总行数，如果select count(*) from table;会直接取出出该值

innodb没有保存表的总行数，如果使用select count(*) from table；就会遍历整个表，消耗相当大，但是在加了wehre       条件后，myisam和innodb处理的方式都一样。

4、全文索引

myisam支持 FULLTEXT类型的全文索引

innodb不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。（sphinx   是一个开源软件，提供多种语言的API接口，可以优化mysql的各种查询）

5、delete from table

使用这条命令时，innodb不会从新建立表，而是一条一条的删除数据，在innodb上如果要清空保存有大量数据的表，最       好不要使用这个命令。(推荐使用truncate table，不过需要用户有drop此表的权限)

6、索引保存位置

myisam的索引以表名+.MYI文件分别保存。

innodb的索引和数据一起保存在表空间里。

### sql注入

就是通过把SQL命令插入到Web[表单](https://baike.baidu.com/item/表单/5380322)提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。

1.永远不要信任用户的输入。对用户的输入进行校验，可以通过[正则表达式](https://baike.baidu.com/item/正则表达式)，或限制长度；对单引号和

双"-"进行转换等。

2.永远不要使用动态拼装sql，可以使用参数化的sql或者直接使用[存储过程](https://baike.baidu.com/item/存储过程)进行数据查询存取。

3.永远不要使用[管理员](https://baike.baidu.com/item/管理员)权限的数据库连接，为每个应用使用单独的权限有限的数据库连接。

4.不要把机密信息直接存放，加密或者hash掉密码和敏感的信息。

5.应用的异常信息应该给出尽可能少的提示，最好使用自定义的[错误信息](https://baike.baidu.com/item/错误信息)对原始错误信息进行包装

6.sql注入的检测方法一般采取辅助[软件](https://baike.baidu.com/item/软件)或网站平台来检测，软件一般采用sql注入检测工具jsky，网站平台就有亿思[网站安全](https://baike.baidu.com/item/网站安全)平台检测工具。MDCSOFT SCAN等。采用[MDCSOFT-IPS](https://baike.baidu.com/item/MDCSOFT-IPS)可以有效的防御SQL注入，XSS攻击等。

## 数据库对比

![image-20191109223550712](/Users/ss/Library/Application Support/typora-user-images/image-20191109223550712.png)

Redis和mencached都可用于存储键值映射，彼此性能也相差无几，但是①.Redis能够自动以两种不同的方式将数据写入硬盘进行持久化；②.Redis除了能存储普通的字符串键外，还可以存储其他四种数据结构，而memcached只能存储普通的字符串键；③.Redis数据库既可以用作主数据库（primary database）使用，也可以作为其他存储系统的辅助数据库（auxiliary database）使用。

##  Redis的数据结构

- STRING：可以是字符串、整数或者浮点数
- LIST：一个链表，链表上的每个节点都包含了一个字符串
- SET：包含字符串的无序收集器（unordered collection），并且被包含的每个字符串都是独一无二、各不相同的
- HAST：包含键值对的无序散列表
- ZSET：字符串成员（member）与浮点数分值（score）之间的有序映射，元素的排列顺序由分值的大小决定

## 分库分表

- 垂直（纵向）切分：把单一的表拆分成多个表，并分散到不同的数据库（主机）上。
- 水平（横向）切分：根据表中数据的逻辑关系，将同一个表中的数据按照某种条件拆分到多台数据库（主机）上。

**垂直切分的优点**

- 拆分后业务清晰，拆分规则明确
- 系统之间进行整合或扩展很容易
- 按照成本、应用的等级、应用的类型等将表放到不同的机器上，便于管理
- 便于实现**动静分离**、**冷热分离**的数据库表的设计模式
- 数据维护简单

**垂直切分的缺点**

- 部分业务表无法关联（Join），只能通过接口方式解决，提高了系统的复杂度
- 受每种业务的不同限制，存在单库性能瓶颈，不易进行数据扩展和提升性能
- 事务处理复杂

**水平切分的优点**

- 单库单表的数据保持在一定的量级，有助于性能的提高
- 切分的表的结构相同，应用层改造较少，只需要增加路由规则即可
- 提高了系统的稳定性和负载能力

**水平切分的缺点**

- 切分后，数据是分散的，很难利用数据库的Join操作，跨库Join性能较差
- 拆分规则难以抽象
- 分片事务的一致性难以解决
- 数据扩容的难度和维护量极大

**垂直切分和水平切分的共同点**

- 存在分布式事务的问题
- 存在跨节点Join的问题
- 存在跨节点合并排序、分页的问题
- 存在多数据源管理的问题

## 主从复制

主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。

- **binlog 线程** ：负责将主服务器上的数据更改写入二进制文件（binlog）中。
- **I/O 线程** ：负责从主服务器上读取二进制日志文件，并写入从服务器的中继日志中。
- **SQL 线程** ：负责读取中继日志并重放其中的 SQL 语句。

# 四、并发

### 线程状态

![image-20190515103921628](/Users/ss/Library/Application Support/typora-user-images/image-20190515103921628.png)

### ![image-20190515103557467](/Users/ss/Library/Application Support/typora-user-images/image-20190515103557467.png)

#### 3.1. interrupted

中断可以理解为线程的一个标志位，它表示了一个运行中的线程是否被其他线程进行了中断操作。中断好比其他线程对该线程打了一个招呼。其他线程可以调用该线程的interrupt()方法对其进行中断操作，同时该线程可以调用
isInterrupted（）来感知其他线程对其自身的中断操作，从而做出响应。另外，同样可以调用Thread的静态方法
interrupted（）对当前线程进行中断操作，该方法会清除中断标志位。**需要注意的是，当抛出InterruptedException时候，会清除中断标志位，也就是说在调用isInterrupted会返回false。**

![image-20190515105328140](/Users/ss/Documents/面试/线程中断.png)

#### 3.2. join

join方法可以看做是线程间协作的一种方式，很多时候，一个线程的输入可能非常依赖于另一个线程的输出，这就像两个好基友，一个基友先走在前面突然看见另一个基友落在后面了，这个时候他就会在原处等一等这个基友，等基友赶上来后，就两人携手并进。其实线程间的这种协作方式也符合现实生活。在软件开发的过程中，从客户那里获取需求后，需要经过需求分析师进行需求分解后，这个时候产品，开发才会继续跟进。如果一个线程实例A执行了threadB.join(),其含义是：当前线程A会等待threadB线程终止后threadA才会继续执行。关于join方法一共提供如下这些方法:

两者主要的区别：

1. sleep()方法是Thread的静态方法，而wait是Object实例方法
2. wait()方法必须要在同步方法或者同步块中调用，也就是必须已经获得对象锁。而sleep()方法没有这个限制可以在任何地方种使用。另外，wait()方法会释放占有的对象锁，使得该线程进入等待池中，等待下一次获取资源。而sleep()方法只是会让出CPU并不会释放掉对象锁；
3. sleep()方法在休眠时间达到后如果再次获得CPU时间片就会继续执行，而wait()方法必须等待Object.notift/Object.notifyAll通知后，才会离开等待池，并且再次获得CPU时间片才会继续执行。

#### 3.3 sleep

public static native void sleep(long millis)方法显然是Thread的静态方法，很显然它是让当前线程按照指定的时间休眠，其休眠时间的精度取决于处理器的计时器和调度器。需要注意的是如果当前线程获得了锁，sleep方法并不会失去锁。sleep方法经常拿来与Object.wait()方法进行比价，这也是面试经常被问的地方。

> **sleep() VS wait()**

两者主要的区别：

1. **sleep()方法是Thread的静态方法，而wait是Object实例方法**
2. wait()方法必须要在同步方法或者同步块中调用，也就是必须已经获得对象锁。而sleep()方法没有这个限制可以在任何地方种使用。另外，wait()方法会释放占有的对象锁，使得该线程进入等待池中，等待下一次获取资源。而sleep()方法只是会让出CPU并不会释放掉对象锁；
3. sleep()方法在休眠时间达到后如果再次获得CPU时间片就会继续执行，而wait()方法必须等待Object.notift/Object.notifyAll通知后，才会离开等待池，并且再次获得CPU时间片才会继续执行。

#### 3.4 yield

public static native void yield();这是一个静态方法，一旦执行，它会是当前线程让出CPU，但是，需要注意的是，让出的CPU并不是代表当前线程不再运行了，如果在下一次竞争中，又获得了CPU时间片当前线程依然会继续运行。另外，让出的时间片只会分配**给当前线程相同优先级**的线程。什么是线程优先级了？下面就来具体聊一聊。

现代操作系统基本采用时分的形式调度运行的线程，操作系统会分出一个个时间片，线程会分配到若干时间片，当前时间片用完后就会发生线程调度，并等待这下次分配。线程分配到的时间多少也就决定了线程使用处理器资源的多少，而线程优先级就是决定线程需要或多或少分配一些处理器资源的线程属性。

在Java程序中，通过一个**整型成员变量Priority**来控制优先级，优先级的范围从1~10.在构建线程的时候可以通过**setPriority(int)**方法进行设置，默认优先级为5，优先级高的线程相较于优先级低的线程优先获得处理器时间片。需要注意的是在不同JVM以及操作系统上，线程规划存在差异，有些操作系统甚至会忽略线程优先级的设定。

另外需要注意的是，sleep()和yield()方法，同样都是当前线程会交出处理器资源，而它们不同的是，sleep()交出来的时间片其他线程都可以去竞争，也就是说都有机会获得当前线程让出的时间片。而yield()方法只允许与当前线程具有相同优先级的线程能够获得释放出来的CPU时间片。

### synchronized 和lock

#### **1.**synchronized能够把任何一个非null对象当成锁，实现由两种方式：

　　a.当synchronized作用于非静态方法时，锁住的是当前对象的事例，当synchronized作用于静态方法时，锁住的是class实例，又因为Class的相关数据存储在永久带，因此静态方法锁相当于类的一个全局锁。

　　b.当synchronized作用于一个对象实例时，锁住的是对应的代码块。

#### 2.synchronized锁又称为对象监视器（object）。

#### 3.当多个线程一起访问某个对象监视器的时候，对象监视器会将这些请求存储在不同的容器中。

　　>Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中

　　>Entry List：Contention List中那些有资格成为候选资源的线程被移动到Entry List中

　　>Wait Set：哪些调用wait方法被阻塞的线程被放置在这里

　　>OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为OnDeck

　　>Owner：当前已经获取到所资源的线程被称为Owner

　　> !Owner：当前释放锁的线程

#### 4.synchronized在jdk1.6之后提供了多种优化方案：

　　**>自旋锁**

　　　　jdk1.6之后默认开启，可以使用参数-XX:+UseSpinning控制，自旋等待不能代替阻塞，且先不说对处理器数量的要求，自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，因此，如果锁被占用的时间很短，自旋等待的效果就会非常好，反之，如果锁被占用的时候很长，那么自旋的线程只会白白消耗处理器资源，而不会做任何有用的工作，反而会带来性能上的浪费。自旋次数的默认值是 10 次，用户可以使用参数 -XX:PreBlockSpin 来更改。

　　　　自旋锁的本质：执行几个空方法，稍微等一等，也许是一段时间的循环，也许是几行空的汇编指令。

　　**>锁消除**

　　　　即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除，依据来源于逃逸分析的数据支持，那么是什么是逃逸分析？对于虚拟机来说需要使用数据流分析来确定是否消除变量底层框架的同步代码，因为有许多同步的代码不是自己写的。

**lock的实现方案**

与synchronized不同的是lock是纯java手写的，与底层的JVM无关。在java.util.concurrent.locks包中有很多Lock的实现类，常用的有ReenTrantLock、ReadWriteLock(实现类有ReenTrantReadWriteLock)

，其实现都依赖java.util.concurrent.AbstractQueuedSynchronizer类（简称AQS），实现思路都大同小异，因此我们以ReentrantLock作为讲解切入点。

分析之前我们先来花点时间看下AQS。AQS是我们后面将要提到的CountDownLatch/FutureTask/ReentrantLock/RenntrantReadWriteLock/Semaphore的基础，因此AQS也是Lock和Excutor实现的基础。它的基本思想就是一个同步器，支持获取锁和释放锁两个操作。

要支持上面锁获取、释放锁就必须满足下面的条件：

　　1、  状态位必须是原子操作的

　　2、  阻塞和唤醒线程

　　3、  一个有序的队列，用于支持锁的公平性

　　场景：可定时的、可轮询的与可中断的锁获取操作，公平队列，或者非块结构的锁。

　　主要从以下几个特点介绍：

　　**1.可重入锁**

　　　　如果锁具备可重入性，则称作为可重入锁。像synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。

　　**2.可中断锁**

　　　　可中断锁：顾名思义，就是可以相应中断的锁。

　　　　在Java中，synchronized就不是可中断锁，而Lock是可中断锁。

　　　　如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。

　　**3.公平锁和非公平锁**

　　　  公平锁以请求锁的顺序来获取锁，非公平锁则是无法保证按照请求的顺序执行。synchronized就是非公平锁，它无法保证等待的线程获取锁的顺序。而对于ReentrantLock和ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁。

　　　　参数为true时表示公平锁，不传或者false都是为非公平锁。

```
ReentrantLock lock = new ReentrantLock(true);
```

　　**4.读写锁**

　　读写锁将对一个资源（比如文件）的访问分成了2个锁，一个读锁和一个写锁。

　　正因为有了读写锁，才使得多个线程之间的读操作不会发生冲突。

　　ReadWriteLock就是读写锁，它是一个接口，ReentrantReadWriteLock实现了这个接口。

　　可以通过readLock()获取读锁，通过writeLock()获取写锁。

　**1.synchronized**

　　优点：实现简单，语义清晰，便于JVM堆栈跟踪，加锁解锁过程由JVM自动控制，提供了多种优化方案，使用更广泛

　　缺点：悲观的排他锁，不能进行高级功能

　　**2.lock**

　　优点：可定时的、可轮询的与可中断的锁获取操作，提供了读写锁、公平锁和非公平锁　　

　　缺点：需手动释放锁unlock，不适合JVM进行堆栈跟踪

　　**3.相同点**　

　　都是可重入锁

### volitail

一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：

　　1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。

　　2）禁止进行指令重排序。

### 线程池

- new CachedThreadPool 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
- new FixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
- new ScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。
- new SingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行

#### 分类

#### 大小

# 五、设计模式

## 分类



### 工厂模式

### 单例模式

单例模式指的是在应用整个生命周期内只能存在一个实例。单例模式是一种被广泛使用的设计模式。他有很多好处，能够避免实例对象的重复创建，减少创建实例的系统开销，节省内存。

#### 1、饿汉式（静态常量）[可用]

```java
public class Singleton {

    private final static Singleton INSTANCE = new Singleton();

    private Singleton(){}

    public static Singleton getInstance(){
        return INSTANCE;
    }
}
```

优点：这种写法比较简单，就是在类装载的时候就完成实例化。避免了线程同步问题。

缺点：在类装载的时候就完成实例化，没有达到Lazy Loading的效果。如果从始至终从未使用过这个实例，则会造成内存的浪费。

#### 2、饿汉式（静态代码块）[可用]

```java
public class Singleton {

    private static Singleton instance;

    static {
        instance = new Singleton();
    }

    private Singleton() {}

    public static Singleton getInstance() {
        return instance;
    }
}
```

这种方式和上面的方式其实类似，只不过将类实例化的过程放在了静态代码块中，也是在类装载的时候，就执行静态代码块中的代码，初始化类的实例。优缺点和上面是一样的。

#### 3、懒汉式(线程不安全)[不可用]

```java
public class Singleton {

    private static Singleton singleton;

    private Singleton() {}

    public static Singleton getInstance() {
        if (singleton == null) {
            singleton = new Singleton();
        }
        return singleton;
    }
}
```

这种写法起到了Lazy Loading的效果，但是只能在单线程下使用。如果在多线程下，一个线程进入了if (singleton == null)判断语句块，还未来得及往下执行，另一个线程也通过了这个判断语句，这时便会产生多个实例。所以在多线程环境下不可使用这种方式。

#### 4、懒汉式(线程安全，同步方法)[不推荐用]

```java
public class Singleton {

    private static Singleton singleton;

    private Singleton() {}

    public static synchronized Singleton getInstance() {
        if (singleton == null) {
            singleton = new Singleton();
        }
        return singleton;
    }
}
```

解决上面第三种实现方式的线程不安全问题，做个线程同步就可以了，于是就对getInstance()方法进行了线程同步。

缺点：效率太低了，每个线程在想获得类的实例时候，执行getInstance()方法都要进行同步。而其实这个方法只执行一次实例化代码就够了，后面的想获得该类实例，直接return就行了。方法进行同步效率太低要改进。

#### 5、懒汉式(线程安全，同步代码块)[不可用]

```java
public class Singleton {

    private static Singleton singleton;

    private Singleton() {}

    public static Singleton getInstance() {
        if (singleton == null) {
            synchronized (Singleton.class) {
                singleton = new Singleton();
            }
        }
        return singleton;
    }
}
```

由于第四种实现方式同步效率太低，所以摒弃同步方法，改为同步产生实例化的的代码块。但是这种同步并不能起到线程同步的作用。跟第3种实现方式遇到的情形一致，假如一个线程进入了if (singleton == null)判断语句块，还未来得及往下执行，另一个线程也通过了这个判断语句，这时便会产生多个实例。

#### 6、双重检查[推荐用]

```java
public class Singleton {

    private static volatile Singleton singleton; //volatile防止代码重排序

    private Singleton() {}

    public static Singleton getInstance() {
        if (singleton == null) { //第一次检查
            synchronized (Singleton.class) {
                if (singleton == null) { //第二次检查
                    singleton = new Singleton();
                }
            }
        }
        return singleton;
    }
}
```

Double-Check概念对于多线程开发者来说不会陌生，如代码中所示，我们进行了两次if (singleton == null)检查，这样就可以保证线程安全了。这样，实例化代码只用执行一次，后面再次访问时，判断if (singleton == null)，直接return实例化对象。

优点：线程安全；延迟加载；效率较高。

#### 7、静态内部类[推荐用]

```java
public class Singleton {

    private Singleton() {}

    private static class SingletonInstance {
        private static final Singleton INSTANCE = new Singleton();
    }

    public static Singleton getInstance() {
        return SingletonInstance.INSTANCE;
    }
}
```

这种方式跟饿汉式方式采用的机制类似，但又有不同。两者都是采用了类装载的机制来保证初始化实例时只有一个线程。不同的地方在饿汉式方式是只要Singleton类被装载就会实例化，没有Lazy-Loading的作用，而静态内部类方式在Singleton类被装载时并不会立即实例化，而是在需要实例化时，调用getInstance方法，才会装载SingletonInstance类，从而完成Singleton的实例化。

类的静态属性只会在第一次加载类的时候初始化，所以在这里，JVM帮助我们保证了线程的安全性，在类进行初始化时，别的线程是无法进入的。

优点：避免了线程不安全，延迟加载，效率高。

#### 8、枚举[推荐用]

```java
public enum Singleton {
    INSTANCE;
    public void whateverMethod() {

    }
}
```

借助JDK1.5中添加的枚举来实现单例模式。不仅能避免多线程同步问题，而且还能防止反序列化重新创建新的对象。可能是因为枚举在JDK1.5中才添加，所以在实际项目开发中，很少见人这么写过。

**优点**

系统内存中该类只存在一个对象，节省了系统资源，对于一些需要频繁创建销毁的对象，使用单例模式可以提高系统性能。

**缺点**

当想实例化一个单例类的时候，必须要记住使用相应的获取对象的方法，而不是使用new，可能会给其他开发人员造成困扰，特别是看不到源码的时候。

**适用场合**

- 需要频繁的进行创建和销毁的对象；
- 创建对象时耗时过多或耗费资源过多，但又经常用到的对象；
- 工具类对象；
- 频繁访问数据库或文件的对象。

# 六、计算机网络

DNS劫持

ARP攻击

运营商劫持http





## OSI七层协议

### 传输层：

传输层主要是提供不同主机上的进程之间的逻辑通信（端到端的通信），即使在不可靠的网络层（主机之间的逻辑通信）传输下，传输层也能提供可靠的传输。（所谓的逻辑通信就是指：传输层之间看似是在水平方向传送数据，但是事实上这两个传输层之间并没有水平方向上的物理连接）

### 网络层：

 网络层是为传输层提供服务的，传送的协议数据单元称为数据包或分组。该层的主要作用是解决如何使数据包通过各结点传送的问题，即通过路径选择算法（路由）将数据包送到目的地。另外，为避免通信子网中出现过多的数据包而造成[网络阻塞](http://baike.baidu.com/view/712723.htm)，需要对流入的数据包数量进行控制（拥塞控制）。当数据包要跨越多个通信子网才能到达目的地时，还要解决网际互连的问题。

### 数据链路层：

在物理层所提供的服务的基础上 向网络层提供服务，即将原始的、有差错的物理线路改进成为逻辑上无差错的数据链路，从而向网络层提供高质量的服务。它一般包括 3 种基本服务：无确定的无连接服务、有确定的有连接服务、有确定的无连接服务（不存在无确定的有连接服务）。 
具体而言，数据链路层的主要功能如下： 
**链路管理**：负责数据链路的建立、维持和释放，主要用于面向连接服务。
**帧同步**：接收方确定收到的比特流中一帧的开始位置和结束位置。
**差错控制**：用于使接收方确定收到的数据就是由发送方发送的数据。
**透明传输**：不论数据是什么样的比特组合，都应当能够在链路上进行传输。

## TCP/UDP

- TCP 是面向连接的，UDP 是面向无连接的
- UDP程序结构较简单
- TCP 是面向字节流的，UDP 是基于数据报的
- TCP 保证数据正确性，UDP 可能丢包
- TCP 保证数据顺序，UDP 不保证

**TCP 为什么是可靠连接**

- 通过 TCP 连接传输的数据无差错，不丢失，不重复，且按顺序到达。
- TCP 报文头里面的序号能使 TCP 的数据按序到达
- 报文头里面的确认序号能保证不丢包，累计确认及超时重传机制
- TCP 拥有流量控制及拥塞控制的机制

TCP 的顺序问题，丢包问题，流量控制都是通过滑动窗口来解决的
拥塞控制时通过拥塞窗口来解决的

![image-20190520182240679](/Users/ss/Documents/面试/TCP.png)

### 1、为什么是三次握手

如果两次，那么B无法确定B的信息A是否能收到，所以如果B先说话，可能后面的A都收不到，会出现问题 。

如果四次，那么就造成了浪费，因为在三次结束之后，就已经可以保证A可以给B发信息，A可以收到B的信息； B可以给A发信息，B可以收到A的信息。

### 2、为什么连接的时候是三次握手，关闭的时候却是四次握手？

答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。

### 3、为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？

答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN片段。所以Client不能立即关闭，它必须确认Server接收到了该ACK。Client会在发送出ACK之后进入到TIME_WAIT状态。Client会设置一个计时器，等待2MSL的时间。如果在该时间内再次收到FIN，那么Client会重发ACK并再次等待2MSL。所谓的2MSL是两倍的MSL(Maximum Segment Lifetime)。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。

### 4、为什么不能用两次握手进行连接？

   现在把三次握手改成仅需要两次握手，死锁是可能发生的。作为例子，考虑计算机S和C之间的通信，假定C给S发送一个连接请求分组，S收到了这个分组，并发 送了确认应答分组。按照两次握手的协定，S认为连接已经成功地建立了，可以开始发送数据分组。可是，C在S的应答分组在传输中被丢失的情况下，将不知道S 是否已准备好，不知道S建立什么样的序列号，C甚至怀疑S是否收到自己的连接请求分组。在这种情况下，C认为连接还未建立成功，将忽略S发来的任何数据组，只等待连接确认应答分组。而S在发出的分组超时后，重复发送同样的分组。这样就形成了死锁。

### 5、如果已经建立了连接，但是客户端突然出现故障了怎么办？

TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

### 2、超时重传

**a.超时重传**超时重传机制用来保证TCP传输的可靠性。每次发送数据包时，发送的数据报都有seq号，接收端收到数据后，会回复ack进行确认，表示某一seq 号数据已经收到。发送方在发送了某个seq包后，等待一段时间，如果没有收到对应的ack回复，就会认为报文丢失，会重传这个数据包。

**b.快速重传**接受数据一方发现有数据包丢掉了。就会发送ack报文告诉发送端重传丢失的报文。如果发送端连续收到标号相同的ack包，则会触发客户端的快速重传。比较超时重传和快速重传，可以发现超时重传是发送端在傻等超时，然后触发重传;而快速重传则是接收端主动告诉发送端数据没收到，然后触发发送端重传。

**c.流量控制**这里主要说TCP滑动窗流量控制。TCP头里有一个字段叫Window，又叫Advertised-Window，这个字段是接收端告诉发送端自己 还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。 滑动窗可以是提高TCP传输效率的一种机制。

**d.拥塞控制**滑动窗用来做流量控制。流量控制只关注发送端和接受端自身的状况，而没有考虑整个网络的通信情况。拥塞控制，则是基于整个网络来考虑的。考虑一下这 样的场景：某一时刻网络上的延时突然增加，那么，TCP对这个事做出的应对只有重传数据，但是，重传会导致网络的负担更重，于是会导致更大的延迟以及更多 的丢包，于是，这个情况就会进入恶性循环被不断地放大。试想一下，如果一个网络内有成千上万的TCP连接都这么行事，那么马上就会形成“网络风 暴”，TCP这个协议就会拖垮整个网络。为此，TCP引入了拥塞控制策略。拥塞策略算法主要包括：慢启动，拥塞避免，拥塞发生，快速恢复。

## 访问网页过程

## cookie 和 session

### Cookie技术

Cookie技术是客户端的解决方案，Cookie就是由服务器发给客户端的特殊信息，而这些信息以**文本文件的方式存放在客户端**，然后客户端每次向服务器发送请求的时候都会带上这些特殊的信息。让我们说得更具体一些：当用户使用浏览器访问一个支持Cookie的网站的时候，用户会提供包括用户名在内的个人信息并且提交至服务器；接着，服务器在向客户端回传相应的超文本的同时也会发回这些个人信息，当然这些信息并不是存放在HTTP响应体（Response Body）中的，而是存放于**HTTP响应头**（Response Header）；当客户端浏览器接收到来自服务器的响应之后，浏览器会将这些信息存放在一个统一的位置，对于Windows操作系统而言，我们可以从： [系统盘]:\Documents and Settings[用户名]\Cookies目录中找到存储的Cookie；自此，客户端再向服务器发送请求的时候，都会把相应的Cookie再次发回至服务器。而这次，Cookie信息则存放在HTTP请求头（Request Header）了。有了Cookie这样的技术实现，服务器在接收到来自客户端浏览器的请求之后，就能够通过分析存放于请求头的Cookie得到客户端特有的信息，从而动态生成与该客户端相对应的内容。通常，我们可以从很多网站的登录界面中看到“请记住我”这样的选项，如果你勾选了它之后再登录，那么在下一次访问该网站的时候就不需要进行重复而繁琐的登录动作了，而这个功能就是通过Cookie实现的。

在程序中，会话跟踪是很重要的事情。理论上，一个用户的所有请求操作都应该属于同一个会话，而另一个用户的所有请求操作则应该属于另一个会话，二者不能混淆。例如，用户A在超市购买的任何商品都应该放在A的购物车内，不论是用户A什么时间购买的，这都是属于同一个会话的，不能放入用户B或用户C的购物车内，这不属于同一个会话。

而Web应用程序是使用HTTP协议传输数据的。HTTP协议是无状态的协议。一旦数据交换完毕，客户端与服务器端的连接就会关闭，再次交换数据需要建立新的连接。这就意味着服务器无法从连接上跟踪会话。即用户A购买了一件商品放入购物车内，当再次购买商品时服务器已经无法判断该购买行为是属于用户A的会话还是用户B的会话了。要跟踪该会话，必须引入一种机制。

Cookie就是这样的一种机制。它可以弥补HTTP协议无状态的不足。在Session出现之前，基本上所有的网站都采用Cookie来跟踪会话。

如果你把Cookies看成为http协议的一个扩展的话，理解起来就容易的多了，其实本质上cookies就是http的一个扩展。有两个http头部是专门负责设置以及发送cookie的,它们分别是Set-Cookie以及Cookie。当服务器返回给客户端一个http响应信息时，其中如果包含Set-Cookie这个头部时，意思就是指示客户端建立一个cookie，并且在后续的http请求中自动发送这个cookie到服务器端，直到这个cookie过期。如果cookie的生存时间是整个会话期间的话，那么浏览器会将cookie保存在内存中，浏览器关闭时就会自动清除这个cookie。另外一种情况就是保存在客户端的硬盘中，浏览器关闭的话，该cookie也不会被清除，下次打开浏览器访问对应网站时，这个cookie就会自动再次发送到服务器端。一个cookie的设置以及发送过程分为以下四步：

> 客户端发送一个http请求到服务器端 服务器端发送一个http响应到客户端，其中包含Set-Cookie头部 客户端发送一个http请求到服务器端，其中包含Cookie头部 服务器端发送一个http响应到客户端

cookie存储的数据量有限，不同的浏览器有不同的存储大小，但一般不超过4KB。因此使用cookie只能存储一些小量的数据。

### Session机制

除了使用Cookie，Web应用程序中还经常使用Session来记录客户端状态。Session是服务器端使用的一种记录客户端状态的机制，使用上比Cookie简单一些，相应的也增加了服务器的存储压力。

Session技术则是服务端的解决方案，它是通过服务器来保持状态的。由于Session这个词汇包含的语义很多，因此需要在这里明确一下 Session的含义。首先，我们通常都会把Session翻译成会话，因此我们可以把客户端浏览器与服务器之间一系列交互的动作称为一个 Session。从这个语义出发，我们会提到Session持续的时间，会提到在Session过程中进行了什么操作等等；其次，Session指的是服务器端为客户端所开辟的存储空间，在其中保存的信息就是用于保持状态。从这个语义出发，我们则会提到往Session中存放什么内容，如何根据键值从 Session中获取匹配的内容等。要使用Session，第一步当然是创建Session了。那么Session在何时创建呢？当然还是在服务器端程序运行的过程中创建的，不同语言实现的应用程序有不同创建Session的方法，而在Java中是通过调用HttpServletRequest的getSession方法（使用true作为参数）创建的。在创建了Session的同时，服务器会为该Session生成唯一的**Session id**，而这个Session id在随后的请求中会被用来重新获得已经创建的Session；在Session被创建之后，就可以调用Session相关的方法往Session中增加内容了，而这些内容只会保存在服务器中，发到客户端的只有Session id；当客户端再次发送请求的时候，会将这个Session id带上，服务器接受到请求之后就会依据Session id找到相应的Session，从而再次使用之。正式这样一个过程，用户的状态也就得以保持了。

Session是另一种记录客户状态的机制，不同的是**Cookie保存在客户端浏览器**中，而**Session保存在服务器**上。客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上。这就是Session。客户端浏览器再次访问时只需要从该Session中查找该客户的状态就可以了。

如果说Cookie机制是通过检查客户身上的“通行证”来确定客户身份的话，那么Session机制就是通过检查服务器上的“客户明细表”来确认客户身份。Session相当于程序在服务器上建立的一份客户档案，客户来访的时候只需要查询客户档案表就可以了。

### Cookie与Session的区别

1. cookie数据存放在客户的浏览器上，session数据放在服务器上；
2. cookie**不是很安全**，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗，考虑到安全应当使用session；
3. session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能。考虑到减轻服务器性能方面，应当使用COOKIE；
4. 单个cookie在客户端的限制是**3K**，就是说一个站点在客户端存放的COOKIE不能超过3K；

Cookie和Session的方案虽然分别属于客户端和服务端，但是服务端的session的实现对客户端的cookie有依赖关系的，上面我讲到服务端执行session机制时候会生成session的id值，这个id值会发送给客户端，客户端每次请求都会把这个id值放到http请求的头部发送给服务端，而这个id值在客户端会保存下来，保存的容器就是cookie，因此当我们完全禁掉浏览器的cookie的时候，服务端的session也会不能正常使用（注意：有些资料说ASP解决这个问题，当浏览器的cookie被禁掉，服务端的session任然可以正常使用，ASP我没试验过，但是对于网络上很多用php和jsp编写的网站，我发现禁掉cookie，网站的session都无法正常的访问）。

## HTTP/HTTPS

### 1、HTTP请求

- 200 - 请求成功
- 301 - 资源（网页等）被永久转移到其它URL
- 401 - Unauthorized  请求要求用户的身份认证
- 403 - Forbidden  服务器理解请求客户端的请求，但是拒绝执行此请求
- 404 - 请求的资源（网页等）不存在
- 500 - 内部服务器错误
- 505 - HTTP Version not supported  服务器不支持请求的HTTP协议的版本，无法完成处理

| 1**  | 信息，服务器收到请求，需要请求者继续执行操作   |
| ---- | ---------------------------------------------- |
| 2**  | 成功，操作被成功接收并处理                     |
| 3**  | 重定向，需要进一步的操作以完成请求             |
| 4**  | 客户端错误，请求包含语法错误或无法完成请求     |
| 5**  | 服务器错误，服务器在处理请求的过程中发生了错误 |

当浏览器向Web服务器发出请求时，它向服务器传递了一个数据块，也就是请求信息，HTTP请求信息由3部分组成：

- 请求行：方法URI协议/版本
- 请求头(Request Header)
- 请求体

下面是一个HTTP请求的例子：

```properties
GET/sample.jspHTTP/1.1
#可接受的响应内容类型
Accept:image/gif.image/jpeg,*/* 
#可接受的响应内容语言列表。
Accept-Language:zh-cn  
#客户端（浏览器）想要优先使用的连接类型
Connection:Keep-Alive 
#表示服务器的域名以及服务器所监听的端口号。如果所请求的端口是对应的服务的标准端口（80），则端口号可以省略。
Host:localhost
#浏览器的身份标识字符串
User-Agent:Mozila/4.0(compatible;MSIE5.01;Window NT5.0)
#可接受的响应内容的编码方式。
Accept-Encoding:gzip,deflate

username=jinqiao&password=1234
```

1. **GET方法**

GET方法是默认的HTTP请求方法，我们日常用GET方法来提交表单数据，然而用GET方法提交的表单数据只经过了简单的编码，同时它将作为URL的一部分向Web服务器发送，因此，如果使用GET方法来提交表单数据就存在着安全隐患上。例如

[Http://127.0.0.1/login.jsp?Name=zhangshi&Age=30&Submit=%cc%E+%BD%BB](http://127.0.0.1/login.jsp?Name=zhangshi&Age=30&Submit=%cc%25E+%BD%BB)

从上面的URL请求中，很容易就可以辩认出表单提交的内容。（？之后的内容）另外由于GET方法提交的数据是作为URL请求的一部分所以提交的数据量不能太大

2. **POST方法**

POST方法是GET方法的一个替代方法，它主要是向Web服务器提交表单数据，尤其是大批量的数据。POST方法克服了GET方法的一些缺点。通过POST方法提交表单数据时，数据不是作为URL请求的一部分而是作为标准数据传送给Web服务器，这就克服了GET方法中的信息无法保密和数据量太小的缺点。因此，出于安全的考虑以及对用户隐私的尊重，通常表单提交时采用POST方法。

　　从编程的角度来讲，如果用户通过GET方法提交数据，则数据存放在QUERY＿STRING环境变量中，而POST方法提交的数据则可以从标准输入流中获取。

### 2、HTTP响应

HTTP应答与HTTP请求相似，HTTP响应也由3个部分构成，分别是：

- 协议状态版本代码描述
- 响应头(Response Header)
- 响应正文

下面是一个HTTP响应的例子：

```properties
HTTP/1.1 200 OK
#服务器的名称
Server:Apache Tomcat/5.0.12
#此条消息被发送时的日期和时间(以RFC 7231中定义的"HTTP日期"格式来表示)
Date:Mon,6Oct2003 13:23:42 GMT
#响应消息体的长度，用8进制字节表示
Content-Length:112
```

HTTP应答码：HTTP应答码也称为状态码，它反映了Web服务器处理HTTP请求状态。HTTP应答码由3位数字构成，其中首位数字定义了应答码的类型：

- 1XX－信息类(Information)，表示收到Web浏览器请求，正在进一步的处理中
- 2XX－成功类（Successful），表示用户请求被正确接收，理解和处理例如：200 OK
- 3XX-重定向类(Redirection)，表示请求没有成功，客户必须采取进一步的动作。
- 4XX-客户端错误(Client Error)，表示客户端提交的请求有错误 例如：404 NOT Found，意味着请求中所引用的文档不存在。403（禁止） 服务器拒绝请求。405（方法禁用） 禁用请求中指定的方法。
- 5XX-服务器错误(Server Error)表示服务器不能完成对请求的处理：如 500

### HTTP和HTTPS的区别

HTTP：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。

HTTPS：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。

HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。

HTTPS和HTTP的区别主要如下：

　　1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。

　　2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。

　　3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

　　4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全

客户端在使用HTTPS方式与Web服务器通信时有以下几个步骤，如图所示。

　　（1）客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。

　　（2）Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。

　　（3）客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。

　　（4）客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。

　　（5）Web服务器利用自己的私钥解密出会话密钥。

　　（6）Web服务器利用会话密钥加密与客户端之间的通信。

![image-20190511115437952](/Users/ss/Documents/面试/https.png)





# 七、注解

## 注解的定义

注解通过 `@interface`关键字进行定义。

```java
public @interface TestAnnotation {
}
```

它的形式跟接口很类似，不过前面多了一个 @ 符号。上面的代码就创建了一个名字为 TestAnnotaion 的注解。

你可以简单理解为创建了一张名字为 TestAnnotation 的标签。

## 元注解

元注解是可以注解到注解上的注解，或者说元注解是一种基本注解，但是它能够应用到其它的注解上面。

如果难于理解的话，你可以这样理解。元注解也是一张标签，但是它是一张特殊的标签，它的作用和目的就是给其他普通的标签进行解释说明的。

元标签有 @Retention、@Documented、@Target、@Inherited、@Repeatable 5 种。

### @Retention

Retention 的英文意为保留期的意思。当 @Retention 应用到一个注解上的时候，它解释说明了这个注解的的**存活时间。**

它的取值如下：

RetentionPolicy.SOURCE 注解只在**源码**阶段保留，在编译器进行编译时它将被丢弃忽视。
RetentionPolicy.CLASS 注解只被保留到**编译**进行的时候，它并不会被加载到 JVM 中。
RetentionPolicy.RUNTIME 注解可以保留到程序**运行**的时候，它会被加载进入到 JVM 中，所以在程序运行时可以获取到它们。

### @Documented

顾名思义，这个元注解肯定是和文档有关。它的作用是能够将注解中的元素包含到 Javadoc 中去。

### @Target

Target 是目标的意思，@Target 指定了注解运用的地方。

类比到标签，原本标签是你想张贴到哪个地方就到哪个地方，但是因为 @Target 的存在，它张贴的地方就非常具体了，比如只能张贴到方法上、类上、方法参数上等等。@Target 有下面的取值

ElementType.ANNOTATION_TYPE 可以给一个注解进行注解
ElementType.CONSTRUCTOR 可以给构造方法进行注解
ElementType.FIELD 可以给属性进行注解
ElementType.LOCAL_VARIABLE 可以给局部变量进行注解
ElementType.METHOD 可以给方法进行注解
ElementType.PACKAGE 可以给一个包进行注解
ElementType.PARAMETER 可以给一个方法内的参数进行注解
ElementType.TYPE 可以给一个类型进行注解，比如类、接口、枚举

### @Inherited

Inherited 是继承的意思，但是它并不是说注解本身可以继承，而是说如果一个超类被 @Inherited 注解过的注解进行注解的话，那么如果它的子类没有被任何注解应用的话，那么这个子类就继承了超类的注解。

### @Repeatable

Repeatable 自然是可重复的意思。@Repeatable 是 Java 1.8 才加进来的，所以算是一个新的特性。

## 注解的使用场景

注解是一系列元数据，它提供数据用来解释程序代码，但是注解并非是所解释的代码本身的一部分。注解对于代码的运行效果没有直接影响。

- 提供信息给编译器： 编译器可以利用注解来探测错误和警告信息
- 编译阶段时的处理： 软件工具可以用来利用注解信息来生成代码、Html文档或者做其它相应处理。
- 运行时的处理： 某些注解可以在程序运行的时候接受代码的提取



# 八、框架

## spring

1.1 什么是Spring

  内部最核心的就是**IOC**了，动态注入，让一个对象的创建不用new了，可以自动的生产，这其实就是利用java里的反射，反射其实就是在运行时动态的去创建、调用对象，Spring就是在运行时，跟xml Spring的配置文件来动态的创建对象，和调用对象里的方法的 。 

 Spring还有一个核心就是**AOP**这个就是面向切面编程，可以为某一类对象 进行监督和控制（也就是 在调用这类对象的具体方法的前后去调用你指定的 模块）从而达到对一个模块扩充的功能。这些都是通过  配置类达到的。 

​      **Spring目的**：就是让对象与对象（模块与模块）之间的关系没有通过代码来关联，都是通过**配置类**说明管理的（Spring根据这些配置 内部通过反射去动态的组装对象）  

​      要记住：Spring是一个容器，凡是在容器里的对象才会有Spring所提供的这些服务和功能。  

Spring里用的最经典的一个设计模式就是：**模板方法模式**。(这里我都不介绍了，是一个很常用的设计模式)， Spring里的配置是很多的，很难都记住，但是Spring里的精华也无非就是以上的两点，把以上两点跟理解了 也就基本上掌握了Spring.

Spring的**IoC**容器是Spring的核心，Spring **AOP**是spring框架的重要组成部分

### IOC

概念：控制权由对象本身转向**容器**；由容器根据配置文件去创建实例并创建各个实例之间的依赖关系  
核心：bean工厂；在Spring中，bean工厂创建的各个实例称作bean  

- **Spring IOC实现原理**
  - 创建xml配置文件，配置要创建的对象类
  - 通过反射创建实例；
  - 获取需要注入的接口实现类并将其赋值给该接口。

- **优点**
  - 解耦合，开发更方便组织分工
  - 高层不依赖于底层（依赖倒置）
  - 是应用更容易测试
  - 因为把对象生成放在了XML里定义，所以当我们需要换一个实现子类将会变成很简单（一般这样的对象都是现实于某种接口的），只要修改XML就可以了，这样我们甚至可以实现对象的热插拨

### AOP

通过**预编译方式和运行期动态代理实现在不修改源代码的情况下给程序动态统一添加功能的一种技术。**即系统级的服务从代码中解耦出来。例如：将**日志记录，性能统计，安全控制，事务处理，异常处理**等代码从业务逻辑代码中划分出来。允许你把遍布应用各处的功能分离出来形成可重用组件。

- **我的理解**
  - AOP（Aspect Oriented Programming ）称为面向切面编程，扩展功能不是修改源代码实现，在程序开发中主要用来解决一些系统层面上的问题，比如日志，事务，权限等待，Struts2的拦截器设计就是基于AOP的思想，是个比较经典的例子。
  - 面向切面编程（aop）是对面向对象编程（oop）的补充
  - 面向切面编程提供声明式事务管理
  - AOP就是典型的代理模式的体现
- **Spring AOP实现原理**
  - 动态代理（利用**反射和动态编译**将代理模式变成动态的）
  - JDK的动态代理
    - JDK内置的Proxy动态代理可以在运行时动态生成字节码，而没必要针对每个类编写代理类
    - JDKProxy返回动态代理类，是目标类所实现接口的另一个实现版本，它实现了对目标类的代理（如同UserDAOProxy与UserDAOImp的关系）
  - cglib动态代理
    - CGLibProxy返回的动态代理类，则是目标代理类的一个子类（代理类扩展了UserDaoImpl类）
    - cglib继承被代理的类，重写方法，织入通知，动态生成字节码并运行

- **优点**
  - 各个步骤之间的良好隔离性
  - 源代码无关性
  - 松耦合
  - 易扩展
  - 代码复用

## MyBatis

 是一款优秀的持久层框架，它**支持定制化 SQL、存储过程以及高级映射**。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生类型、接口和 Java 的 POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。

**流程**：

读取核心配置文件并返回InputStream流对象。

根据InputStream流对象解析出Configuration对象，然后创建SqlSessionFactory工厂对象

根据一系列属性从SqlSessionFactory工厂中创建SqlSession

从SqlSession中调用Executor执行数据库操作&&生成具体SQL指令

对执行结果进行二次封装

提交与事务



**（1）SqlSession简单原理介绍**

　　SqlSession提供select/insert/update/delete方法，在旧版本中使用使用SqlSession接口的这些方法，但是新版的Mybatis中就会建议使用Mapper接口的方法。

　　映射器其实就是一个动态代理对象，进入到MapperMethod的execute方法就能简单找到SqlSession的删除、更新、查询、选择方法，从底层实现来说：通过动态代理技术，让接口跑起来，之后采用命令模式，最后还是采用了SqlSession的接口方法（getMapper()方法等到Mapper）执行SQL查询（也就是说Mapper接口方法的实现底层还是采用SqlSession接口方法实现的）。

　　注：以上虽然只是简单的描述，但实际上源码相对复杂，下面将结合源码进行简单的介绍！

**（2）SqlSession重要的四个对象**

　　　　1）Execute：调度执行StatementHandler、ParmmeterHandler、ResultHandler执行相应的SQL语句；

　　　　2）StatementHandler：使用数据库中Statement（PrepareStatement）执行操作，即底层是封装好了的prepareStatement；

　　　　3）ParammeterHandler：处理SQL参数；

　　　　4）ResultHandler：结果集ResultSet封装处理返回。

## SpringMVC

SpringMVC是一种基于Java，实现了**Web MVC**设计模式，**请求驱动类型的轻量级Web框架**，即使用了MVC架构模式的思想，将Web层进行职责解耦。基于请求驱动指的就是使用请求-响应模型，框架的目的就是帮助我们简化开发，SpringMVC也是要简化我们日常Web开发。

# 九、linux命令

查看端口号 netstat

```properties
netstat -nap | grep 1095
```

## ps：查看进程

a  显示所有进程
-a 显示同一终端下的所有程序
-A 显示所有进程
c  显示进程的真实名称
-N 反向选择
-e 等于“-A”
**e  显示环境变量**
**f  显示程序间的关系**
-H 显示树状结构
r  显示当前终端的进程
T  显示当前终端的所有程序
u  指定用户的所有进程
-au 显示较详细的资讯
-aux 显示所有包含其他使用者的行程 
-C<命令> 列出指定命令的状况
--lines<行数> 每页显示的行数
--width<字符数> 每页显示的字符数
--help 显示帮助信息
--version 显示版本显示

实例1：显示所有进程信息

```
$ ps -A
```

实例2：显示指定用户信息

```
$ ps -u root
```

实例3：显示所有进程信息，连同命令行

```properties
$ ps -ef

 UID   PID  PPID   C STIME   TTY           TIME CMD
    0     1     0   0 19 819  ??        19:28.06 /sbin/launchd
    0    39     1   0 19 819  ??         0:23.93 /usr/sbin/syslogd
    0    40     1   0 19 819  ??         0:30.68 /usr/libexec/UserEventAgent (System)
    0    43     1   0 19 819  ??         0:09.15 /System/Library/PrivateFrameworks/Uninstall.framework/Resources/uninstalld
    0    44     1   0 19 819  ??         0:50.42 /usr/libexec/kextd
    0    45     1   0 19 819  ??         4:26.54 /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/FSEvents.framework/Versions/A/Support/fseventsd
```

实例4： ps 与grep 常用组合用法，查找特定进程

```
$ ps -ef|grep ssh
```

实例6：列出目前所有的正在内存当中的程序

```
$ ps aux
```

```
USER：该 process 属于那个使用者账号的
PID ：该 process 的号码
%CPU：该 process 使用掉的 CPU 资源百分比
%MEM：该 process 所占用的物理内存百分比
VSZ ：该 process 使用掉的虚拟内存量 (Kbytes)
RSS ：该 process 占用的固定的内存量 (Kbytes)
TTY ：该 process 是在那个终端机上面运作，若与终端机无关，则显示 ?，另外， tty1-tty6 是本机上面的登入者程序，若为 pts/0 等等的，则表示为由网络连接进主机的程序。
STAT：该程序目前的状态，主要的状态有
R ：该程序目前正在运作，或者是可被运作
S ：该程序目前正在睡眠当中 (可说是 idle 状态)，但可被某些讯号 (signal) 唤醒。
T ：该程序目前正在侦测或者是停止了
Z ：该程序应该已经终止，但是其父程序却无法正常的终止他，造成 zombie (疆尸) 程序的状态
START：该 process 被触发启动的时间
TIME ：该 process 实际使用 CPU 运作的时间
COMMAND：该程序的实际指令
```

可以使用以下命令查使用内存最多的K个进程

```
$ ps -aux | sort -k4nr | head -K
```


如果是10个进程，K=10，如果是最高的三个，K=3

sort -k4nr中（k代表从第几个位置开始，后面的数字4即是其开始位置，结束位置如果没有，则默认到最后；n指代numberic sort，根据其数值排序；r指代reverse，这里是指反向比较结果，输出时默认从小到大，反向后从大到小。）。本例中，可以看到%MEM在第4个位置，根据%MEM的数值进行由大到小的排序。

杀死进程

```properties
kill -9 1095
```

## top：实时显示进程的状态

默认状态显示的是**cpu密集型**的进程，并且**每5秒钟更新一次。你可以通过PID**的数字大小，age (newest first), time (cumulative time),resident memory usage（常驻内存使用）以及进程从启动后占用cpu的时间。

```properties
PID    COMMAND      %CPU TIME     #TH   #WQ  #PORT MEM    PURG   CMPRS  PGRP
81003  top          4.1  00:00.43 1/1   0    25    3744K+ 0B     0B     81003
80996  bash         0.0  00:00.01 1     0    21    800K   0B     0B     80996
80995  login        0.0  00:00.02 2     1    30    1208K  0B     0B     80995
80974  Terminal     39.8 00:06.83 10    5    286-  59M+   13M    0B     80974
80970  mdworker_sha 0.0  00:00.08 3     1    59    4328K  0B     0B     80970
80969  mdworker_sha 0.0  00:00.06 3     1    63    3432K  0B     0B     80969
80966  Google Chrom 0.0  00:00.09 13    1    111   13M    0B     0B     80680
80965  MTLCompilerS 0.0  00:00.31 2     2    24    12M    0B     0B     80965
```

```
PID: 进程描述符 
USER： 进程的拥有者 
PRI：进程的优先级 
NI： nice level 
SIZE: 进程拥有的内存（包括code segment + data segment + stack segment） 
RSS: 物理内存使用
VIRT（virtul memory usage）: 进程需要的虚拟内存大小
RES(resident memory usage)： 常驻内存 
SHARE: 和其他进程共享的物理内存空间 
STAT：进程的状态，有 S=sleeping，R=running，T=stopped or traced，D=interruptible sleep（不可中断的睡眠状态），Z=zombie。 
%CPU： CPU使用率 
%MEM： 物理内存的使用
TIME： 进程占用的总共cpu时间 
COMMAND：进程的命令
```

### 常用的命令

(1) **t**: 用于是否显示总的统计数据，也就是下面这两行

```
Tasks:  65 total,   2 running,  63 sleeping,   0 stopped,   0 zombie
Cpu(s):  0.2%us,  0.1%sy,  0.0%ni, 99.6%id,  0.1%wa,  0.0%hi,  0.0%si,  0.0%st
```

（2）**m**：用户是否显示内存的信息，也就是下面这两行

```
Mem:    500472k total,   282756k used,   217716k free,    82496k buffers    
Swap:        0k total,        0k used,        0k free,    61052k cached
```

（3）**A**： 根据单窗口切换成多窗口，可以看到四个不同的窗口，可以通过a或者w来切换多个窗口。 四个窗口的名字分别为：**Def，Job，Mem，Usr**

（4）**f：**进入一个动态配置top的screen中，可以根据自己的喜好配置top

（5）**o：**对top的现有配置排序（order）

（6）**r：**使用renice命令

（7）**k：**使用kill命令

### top的命令行使用方式

（1） 批量处理模式

```
$ top -b 
```

加上`-b`后，top显示的时候，将每一次显示的结果都打印出来，不会将上一次的结果给冲掉。

（2） 显示某个进程的信息

```
$ top -p pid
```

如果是多个进程，只要如下：

```
$ top -p pid1,pid2,pid3
```

(3) 显示某个用户的进程信息

```
$ top -u username
```

(4) 显示线程的信息，而不是进程的信息

```
$ top -H 
```

(5) 设置刷屏的时间(单位为s)

```
$ top -d ntime
```

## 查看文件

less，more，cat ，tail，head，vim

## awk

pattern { action }

是单个模式-动作语句；对于第三个字段为0的每行，打印其第一个字段。

```properties
$3 == 0 { print $1 }
```



搜索/etc/passwd有root关键字的所有行

```properties
`awk`  `'/root/'` `/etc/passwd` `【这种是pattern的使用，匹配了pattern(这里是root)的行才会执行action(没有指定action，默认输出每行的内容)】`
```

# 十、操作系统

## 分页、分段

### 分页

用户程序的地址空间被划分成若干固定大小的区域，称为“页”，相应地，内存空间分成若干个物理块，页和块的大小相等。可将用户程序的任一页放在内存的任一块中，实现了离散分配。

在执行一个程序之前，内存管理器需要的准备工作：

1) 确定程序的页数

2) 在主存中留出足够的空闲页面

3) 将程序的所有页面载入主存里。（静态的分页，页面无需连续）

### 分段

页面是主存物理空间中划分出来的等长的固定区域。分页方式的优点是页长固定，因而便于构造页表、易于管理，且不存在外碎片。但分页方式的缺点是页长与程序的逻辑大小不相关。例如，某个时刻一个子程序可能有一部分在主存中，另一部分则在辅存中。这不利于编程时的独立性，并给换入换出处理、存储保护和存储共享等操作造成麻烦。

另一种划分可寻址的存储空间的方法称为分段。段是按照程序的自然分界划分的长度可以动态改变的区域。通常，程序员把子程序、操作数和常数等不同类型的数据划分到不同的段中，并且每个程序可以有多个相同类型的段。

 段表本身也是一个段，可以存在辅存中，但一般是驻留在主存中。

将用户程序地址空间分成若干个大小不等的段，每段可以定义一组相对完整的逻辑信息。存储分配时，以段为单位，段与段在内存中可以不相邻接，也实现了离散分配。

## 死锁的条件

- **互斥条件**(Mutual exclusion)  ：资源不能被共享，只能由一个进程使用。     
- **请求与保持条件**(Hold and wait)：进程已获得了一些资源，但因请求其它资源被阻塞时，对已获得的资源保持不放。  
- **不可抢占条件**(No pre-emption)：有些系统资源是不可抢占的，当某个进程已获得这种资源后，系统不能强行收回，只能由进程使用完时自己释放。      
- **循环等待条件**(Circular wait)：若干个进程形成环形链，每个都占用对方申请的下一个资源。** 处理死锁的策略

1、忽略该问题。例如**鸵鸟算法**。

2、检测死锁并且恢复。 3、仔细地对资源进行动态分配，以避免死锁。 4、通过破除死锁四个必要条件之一，来防止死锁产生。

**鸵鸟算法：**

该算法可以应用在极少发生死锁的的情况下。为什么叫鸵鸟算法呢，因为传说中鸵鸟看到危险就把头埋在地底下，可能鸵鸟觉得看不到危险也就没危险了吧。跟掩耳盗铃有点像。

### **银行家算法：**

​        所谓银行家算法，是指在分配资源之前先看清楚，资源分配后是否会导致系统死锁。**如果会死锁，则不分配，否则就分配。**

**按照银行家算法的思想，当进程请求资源时，系统将按如下原则分配系统资源：**

(1) 当一个进程对资源的最大需求量不超过系统中的资源数时可以接纳该进程。

(2) 进程可以分期请求资源，当请求的总数不能超过最大需求量。

(3) 当系统现有的资源不能满足进程尚需资源数时，对进程的请求可以推迟分配，但总能使进程在有限的时间里得到资源。

(4) 当系统现有的资源能满足进程尚需资源数时，必须测试系统现存的资源能否满足该进程尚需的最大资源数，若能满足则按当前的申请量分配资源，否则也要推迟分配。

## 进程间通信

#### 1、管道pipe

管道是**单向的、先进先出的、无结构的、固定大小的字节流**，它把一个进程的标准输出和另一个进程的标准输入连接在一起。写进程在管道的尾端写入数据，读进程在管道的首端读出数据。数据读出后将从管道中移走，其它读进程都不能再读到这些数据。

管道提供了简单的流控制机制，进程试图读空管道时，在有数据写入管道前，进程将一直阻塞。同样地，管道已经满时，进程再试图写管道，在其它进程从管道中移走数据之前，写进程将一直阻塞。

管道有三种：

① 普通管道：有两个限制：一是只支持半双工通信方式，即只能单向传输；二是只能在父子进程之间使用；

② 流管道：去除第一个限制，支持双向传输；

③ 命名管道：去除第二个限制，可以在不相关进程之间进行通信。

#### 2、共享内存

共享内存就是映射一段能被其它进程所访问的内存，这段共享内存由一个进程创建，但**多个进程都可以访问**。共享内存是**最快**的 IPC 方式，它是针对其它进程间通信方式运行效率低而专门设计的。它往往与其它通信机制（如信号量）配合使用，来实现进程间的同步和通信。

#### 3、消息队列

消息的链表， 存放于内核并由队列标识符标识；克服了缓冲区大小受限，信号信息有限，管道无格式字节流等缺点。

#### 4、信号

用于通知某个进程某个事件已经发生，可触发进程已注册的处理函数。

#### 5、信号量

一种计数器，用来控制多个进程对共享资源的访问， 通常作为一种锁机制， 常应用于进程间或进程内多个线程的同步。

#### 6、Socket

通过套接字通信，也可用于不同host之间的进程见通信。

## 进程、线程

### 进程和线程的区别

- 进程是资源分配的最小单位，线程是程序执行的最小单位。
- 进程有自己的独立地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段，这种操作非常昂贵。而线程是共享进程中的数据的，使用相同的地址空间，因此CPU切换一个线程的花费远比进程要小很多，同时创建一个线程的开销也比进程要小很多。
- 线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要以通信的方式（IPC)进行。不过如何处理好同步与互斥是编写多线程程序的难点。
- 但是多进程程序更健壮，多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间。

### 进程同步

#### 1、临界区（CriticalSection）（进程内线程同步）

一次只能被一个进程所占用的资源为**临界资源**；进程内访问临界资源的代码就是**临界区**。为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

#### 2、 同步与互斥

同步指多个进程按**一定顺序**执行；互斥指多个进程在**同一时刻只有一个进程能进入临界区**。同步是在对临界区互斥访问的基础上，通过其它机制来实现有序访问的。

#### 2、事件

基于事件机制， 一个进程/线程主动唤醒另一个进程/线程；比如监听通信端口A。

#### 3、互斥量（Mutex）

类似临界区，但是能在进程间使用。Futex由一块能被多个进程共享的内存空间(对齐后的整型变量)组成, 保存在用户空间的共享内存中，通过原子操作进行操作。操作基本在用户空间内进行(需要仲裁时使用系统内核调用), 减少了系统调用次数， 提供系统性能。

原语：为完成某些特定功能而编制的一段系统程序，它在执行时不可分割、不可中断。原语操作也称为“**原子操作**”。

#### 4、信号量(Semphore)

信号量建立在原子操作上，使用信号量可以用来限制共享资源的线程数目。

**信号量（Samaphore）**是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

- **P** : 如果信号量大于 0 ，执行 - 1 操作；如果信号量等于 0，将进程睡眠，等待信号量大于 0；
- **V**：对信号量执行 + 1 操作，并且唤醒睡眠的进程，让进程完成 P 操作。

P 和 V 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了**互斥量（Mutex）**，0 表示临界区已经加锁，1 表示临界区解锁。

### 线程通信

共享内存和消息传递

#### 方式一：使用 *volatile* 关键字

基于 ***volatile*** 关键字来实现线程间相互通信是使用共享内存的思想，大致意思就是多个线程同时监听一个变量，当这个变量发生变化的时候 ，线程能够感知并执行相应的业务。这也是最简单的一种实现方式

#### 方式二：使用Object类的wait() 和 notify() 方法

众所周知，*Object*类提供了线程间通信的方法：*wait()*、*notify()*、*notifyaAl()*，它们是多线程通信的基础，而这种实现方式的思想自然是线程间通信。

#### 方式三：使用JUC工具类 CountDownLatch

jdk1.5之后在java.util.concurrent包下提供了很多并发编程相关的工具类，简化了我们的并发编程代码的书写，***CountDownLatch***基于AQS框架，相当于也是维护了一个线程间共享变量state

#### 方式五：基本LockSupport实现线程间的阻塞和唤醒

***LockSupport*** 是一种非常灵活的实现线程间阻塞和唤醒的工具，使用它不用关注是等待线程先进行还是唤醒线程先运行，但是得知道线程的名字。

### 生产者-消费者

使用一个互斥量 mutex 来对临界资源进行访问；empty 记录空缓冲区的数量，full 记录满缓冲区的数量。

注意，必须**先执行 P 操作再用互斥量对临界区加锁**，否则会出现死锁。如果都先对临界区加锁，然后再执行 P 操作，考虑这种情况：生产者对临界区加锁后，执行 P(empty) 操作，发现 empty = 0，此时生成者睡眠。消费者此时不能进入临界区，因为生产者对临界区加锁了，也就无法对执行 V(empty) 操作，那么生产者和消费者就会一直等待下去。

### 哲学家吃饭

1) 关系分析。5名哲学家与左右邻居对其中间筷子的访问是互斥关系。

2) 整理思路。显然这里有五个进程。本题的关键是如何让一个哲学家拿到左右两个筷子而不造成死锁或者饥饿现象。那么解决方法有两个，一个是让他们同时拿两个筷子；二是对每个哲学家的动作制定规则，避免饥饿或者死锁现象的发生。

**为避免死锁，可以使用以下三种策略：**

**策略一**原理：至多只允许四个哲学家同时进餐，以**保证至少有一个哲学家能够进餐**，最终总会释放出他所使用过的两支筷子，从而可使更多的哲学家进餐。定义信号量count，只允许4个哲学家同时进餐，这样就能保证至少有一个哲学家可以就餐。

**策略二**原理：仅当哲学家的左右两支筷子都可用时，才允许他拿起筷子进餐。可以利用AND 型信号量机制实现，也可以利用信号量的保护机制实现。利用信号量的保护机制实现的思想是通过记录型信号量mutex对取左侧和右侧筷子的操作进行保护，使之成为一个原子操作，这样可以防止死锁的出现。

**策略三**原理：规定奇数号的哲学家先拿起他左边的筷子，然后再去拿他右边的筷子；而偶数号的哲学家则先拿起他右边的筷子，然后再去拿他左边的筷子。按此规定，将是1、2号哲学家竞争1号筷子，3、4号哲学家竞争3号筷子。即五个哲学家都竞争奇数号筷子，获得后，再去竞争偶数号筷子，最后总会有一个哲学家能获得两支筷子而进餐。

# 十一、git命令

add

commite

Branch

Checkout 

pull

push

log

Config

# 十二、安全

## 密码

分组密码有五种工作体制：

1.电码本模式（Electronic Codebook Book (ECB)）；

2.密码分组链接模式（Cipher Block Chaining (CBC)）；

3.计算器模式（Counter (CTR)）；

4.密码反馈模式（Cipher FeedBack (CFB)）；

5.输出反馈模式（Output FeedBack (OFB)）。

## sql注入

就是通过把SQL命令插入到Web[表单](https://baike.baidu.com/item/表单/5380322)提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。

1.永远不要信任用户的输入。对用户的输入进行校验，可以通过[正则表达式](https://baike.baidu.com/item/正则表达式)，或限制长度；对单引号和

双"-"进行转换等。

2.永远不要使用动态拼装sql，可以使用参数化的sql或者直接使用[存储过程](https://baike.baidu.com/item/存储过程)进行数据查询存取。

3.永远不要使用[管理员](https://baike.baidu.com/item/管理员)权限的数据库连接，为每个应用使用单独的权限有限的数据库连接。

4.不要把机密信息直接存放，加密或者hash掉密码和敏感的信息。

5.应用的异常信息应该给出尽可能少的提示，最好使用自定义的[错误信息](https://baike.baidu.com/item/错误信息)对原始错误信息进行包装

6.sql注入的检测方法一般采取辅助[软件](https://baike.baidu.com/item/软件)或网站平台来检测，软件一般采用sql注入检测工具jsky，网站平台就有亿思[网站安全](https://baike.baidu.com/item/网站安全)平台检测工具。MDCSOFT SCAN等。采用[MDCSOFT-IPS](https://baike.baidu.com/item/MDCSOFT-IPS)可以有效的防御SQL注入，XSS攻击等。

## ARP欺骗

单向欺骗:是指欺骗网关
双向欺骗:是欺骗网关跟被攻击的两个机器

检测被欺骗的主机
可以利用ARPkiller的”Sniffer杀手”扫描整个局域网IP段，然后查找处在”混杂”模式下的计算机，就可以发现对方了.（绿帽子图标是正常模式，红帽子是混杂模式用户）
使用tracert命令在任意一台受影响的主机上，在DOS命令窗口下运行如下命令：tracert 外网ip。
原理：
中毒主机在受影响主机和网关之间，扮演了“中间人”的角色。所有本应该到达网关的数据包，由于错误的MAC地址，均被发到了中毒主机。此时，中毒主机越俎代庖，起了缺省网关的作用。
通俗讲tracert命令是看ping这个外网时进过了哪些ip，如果主机被ARP欺骗，使用这个命令就会暴露攻击者ip，因为我们访问外网时攻击者电脑成了中间人所以下一跳就是它的ip

**防御**

双绑定， 本地跟路由都做了绑定(注:mac地址绑定)
采用ARP防火墙

**ARP病毒攻击症状**

打开网页速度非常慢，甚至打不开
提示IP地址冲突
甚至导致校园网瘫痪断网
一般会绑定木马病毒，窃取用户账号密码

## DNS欺骗

首先欺骗者向目标机器发送构造好的ARP应答数据包，ARP欺骗成功后，嗅探到对方发出的DNS请求数据包，分析数据包取得ID和端口号后，向目标发送自己构造好的一个DNS返回包，对方收到DNS应答包后，发现ID和端口号全部正确，即把返回数据包中的域名和对应的IP地址保存进DNS缓存表中，而后来的当真实的DNS应答包返回时则被丢弃。

1.因为DNS欺骗前提也需要ARP欺骗成功。所以首先做好对ARP欺骗攻击的防范

2.不要依赖于DNS，尽管这样会很不方便，可以使用hosts文件来实现相同的功能；

3.使用安全检测软件定期检查系统是否遭受攻击

4.使用DNSSEC：DNS安全扩展，是由IETF提供的一系列DNS安全认证的机制（可参考RFC2535）。它提供了一种来源鉴定和数据完整性的扩展，但不去保障可用性、加密性和证实域名不存在。开发 DNSSEC 技术的目的之一是通过对数据进行数字“签名”来抵御此类攻击

## XSS攻击

XSS（Cross Site Scripting）攻击全称跨站脚本攻击，是为不和层叠样式表(Cascading Style Sheets, CSS)的缩写混淆，故将跨站脚本攻击缩写为XSS，XSS是一种经常出现在web应用中的计算机安全漏洞，它允许恶意web用户将代码植入到提供给其它用户使用的页面中。比如这些代码包括HTML代码和客户端脚本。

### 1.反射性

反射型XSS，也叫非持久型XSS，是指发生请求时，XSS代码出现在请求URL中，作为参数提交到服务器，服务器解析并响应。响应结果中包含XSS代码，最后浏览器解析并执行。从概念上可以看出，反射型XSS代码是首先出现在URL中的，然后需要服务端解析，最后需要浏览器解析之后XSS代码才能够攻击。

　　这类通常使用URL，具体流程：

　　1、Alice给Bob发送一个恶意构造了Web的URL。
　　2、Bob点击并查看了这个URL。
　　3、恶意页面中的JavaScript打开一个具有漏洞的HTML页面并将其安装在Bob电脑上。
　　4、具有漏洞的HTML页面包含了在Bob电脑本地域执行的JavaScript。
　　5、Alice的恶意脚本可以在Bob的电脑上执行Bob所持有的权限下的命令。

### 2.存储型

　　存储型XSS，也叫持久型XSS，主要是将XSS代码发送到服务器（不管是数据库、内存还是文件系统等。），然后在下次请求页面的时候就不用带上XSS代码了。最典型的就是留言板XSS。用户提交了一条包含XSS代码的留言到数据库。当目标用户查询留言时，那些留言的内容会从服务器解析之后加载出来。浏览器发现有XSS代码，就当做正常的HTML和JS解析执行。XSS攻击就发生了。

## DDOS

**a）资源消耗类攻击**

资源消耗类是比较典型的DDoS攻击，最具代表性的包括：Syn Flood、Ack Flood、UDP
Flood。这类攻击的目标很简单，就是通过大量请求消耗正常的带宽和协议栈处理资源的能力，从而达到服务端无法正常工作的目的。

**b）服务消耗性攻击**

相比资源消耗类攻击，服务消耗类攻击不需要太大的流量，它主要是针对服务的特点进行精确定点打击，如web的CC，数据服务的检索，文件服务的下载等。这类攻击往往不是为了拥塞流量通道或协议处理通道，它们是让服务端始终处理高消耗型的业务的忙碌状态，进而无法对正常业务进行响应，详细示意图如下：

**c）反射类攻击**

反射攻击也叫放大攻击，该类攻击以UDP协议为主，一般请求回应的流量远远大于请求本身流量的大小。攻击者通过流量被放大的特点以较小的流量带宽就可以制造出大规模的流量源，从而对目标发起攻击。反射类攻击严格意义上来说不算是攻击的一种，它只是利用某些服务的业务特征来实现用更小的代价发动Flood攻击

**d）混合型攻击**

混合型攻击是结合上述几种攻击类型，并在攻击过程中进行探测选择最佳的攻击方式。混合型攻击往往伴随这资源消耗和服务消耗两种攻击类型特征。

# 十三、内存溢出和内存泄露

**内存泄漏（memory leak）：**是指程序在申请内存后，**无法释放已申请的内存空间**，导致系统无法及时回收内存并且分配给其他进程使用。通常少次数的内存无法及时回收并不会到程序造成什么影响，但是如果在内存本身就比较少获取多次导致内存无法正常回收时，就会导致内存不够用，最终导致内存溢出。
**内存溢出 （out of memory）：**:指程序申请内存时，**没有足够的内存供申请者使用**，导致数据无法正常存储到内存中。也就是说给你个int类型的存储数据大小的空间，但是却存储一个long类型的数据，这样就会导致内存溢出。

## 内存溢出和内存泄露的关系以及区别

1.关系：内存泄露最终会导致内存溢出，由于系统中的内存是有限的，如果过度占用资源而不及时释放，最后会导致内存不足，从而无法给所需要存储的数据提供足够的内存，从而导致内存溢出。导致内存溢出也可能是由于在给数据分配大小时没有根据实际要求分配，最后导致分配的内存无法满足数据的需求，从而导致内存溢出。

2.区别：内存泄露是由于GC无法及时或者无法识别可以回收的数据进行及时的回收，导致内存的浪费；内存溢出是由于数据所需要的内存无法得到满足，导致数据无法正常存储到内存中。内存泄露的多次表现就是会导致内存溢出。

## java内存泄漏

**性能相关**: 通常出现在大量的对象创建和删除，长时间的垃圾回收延迟，大量的操作系统内存页交换等情况。
**资源限制**: 常常出现在内存不足或内存碎片太大而无法分配大对象时，常常发生在native memory，或者heap memory中；
**Java堆泄漏**: 最经典的内存泄漏场景，出现在Java对象持续被创建，但是并没有被及时释放。常常因为潜在的对象引用导致。
**Native memory泄漏**: 与Java Heap memory外的持续增长的内存利用率相关，例如JNI代码、驱动程序或JVM分配所分配的。
